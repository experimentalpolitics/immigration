---
title: "Reliable Sources?^[Presented at the 2020 Annual Meeting of the International Society for Political Psychology. We thank Jennifer Jerit for helpful comments on previous versions of this manuscript.]"
subtitle: "Correcting Misinformation in Polarized Media Environments"
author:
  - "Patrick W. Kraft^[Corresponding author, kraftp@uwm.edu]"
  - Nicholas R. Davis
  - Taraleigh Davis
  - Amanda Heideman
  - Jason T. Neumeyer
  - Shin Young Park
date: |
  |
  | University of Wisconsin-Milwaukee 
  |
  | \today
  |
  |
abstract: >-
  Various pressing issues at the center of today's politics--such as immigration, climate change, or the recent coronavirus pandemic--are imbued with misinformation. A growing body of research therefore explores the potential impact of providing corrective information. However, while such interventions appear to reduce people's factual misperceptions, they have little to no effect on their underlying attitudes. This study examines how the impact of corrective information on beliefs and attitudes is moderated by media choice. In our survey experiment, participants are asked to read a news article published by Fox News or MSNBC, each highlighting the positive economic impact of legal immigration in the United States. While the news content is held constant across sources, our treatment manipulates whether participants are allowed to freely choose a media outlet or are randomly assigned to one of them. Our results illustrate how people's media choice moderates the effectiveness of corrective information: While factual misperceptions are easily corrected regardless of how people gained access to the information, subsequent opinion change is conditional on people's prior willingness to seek out alternative sources. As such, encouraging people to broaden their media diet may be more effective to combat misinformation than disseminating fact-checks alone.
reference-section-title: References
bibliography: '../../bibliography/Lab.bib'
fontsize: 12pt
geometry: margin=1in
linestretch: 1.5
output: 
  pdf_document:
    number_sections: false
    template: null
    fig_caption: yes
header-includes:
  \renewcommand{\familydefault}{\sfdefault}
  \usepackage{float}
  \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r code}
## Load packages, data, analyses
source("../code/02-analysis.R")
```

\clearpage


Citizens in western democracies hold wide-ranging and systematic misperceptions about immigrants to their home countries. For example, people usually overestimate the total number of immigrants or the proportion of immigrants that are dependent on social welfare [e.g., @alesina2019immigration]. Given this extensive spread of misinformation, various studies examined how corrective information may affect people's underlying attitudes towards immigration, albeit with limited success. Although corrective information may alleviate factual misperceptions, it rarely affects people's underlying attitudes [see for example @hopkins2019muted; @thompson2019might].

A possible explanation for this apparent disconnect could be that factual information is simply irrelevant for attitude formation and---if anything---serves as a mere justification for people to rationalize their existing predispositions towards immigrant populations. However, the extent to which people engage such motivated reasoning is not without limits---as people have been shown to update their prior beliefs after reaching a "tipping point" of counter-attitudinal information [@redlawsk2010affective]. Furthermore, recent research on immigration attitudes demonstrate the persuasiveness of certain interventions such as canvassing [@kalla2020reducing].

Why do researchers frequently fail to find evidence of attitude change after providing respondents with corrective information? We argue that most experimental designs in this area are inconclusive because they omit a crucial mechanism: people's discretion over whether to engage with a given information source or not. Specifically, studies usually employ simple random assignment of informational treatments without considering people's selective exposure. *Unfortunately, such a set-up does not allow us to estimate the effect of misinformation corrections among people who would have chosen to access their preferred source to update information in the first place.* [@benedictis2019persuading; @knox2019design]. <!-- Need to be clear  -->

We address these shortcomings of previous research by implementing an experimental design that varies both the source of misinformation corrections, as well as the process through which people access the information. Specifically, we conduct an online survey experiment on the effectiveness of corrective information about immigration. Depending on the experimental condition, participants are either able to freely choose--or are assigned to--an article published by different news channels (Fox News vs. MSNBC), which discusses the economic impact of legal immigration. Crucially, our design allows us to differentiate how the information treatment impacts factual beliefs, how they are interpreted, as well as broader attitudes towards immigration. The results indicate that while the correction of factual misperceptions does not depend on media choice, subsequent attitude change is conditional on people's willingness to seek out alternative sources.

Taking into account endogenous information search in studies of misinformation corrections is crucial in our rapidly changing media environment where people have unprecedented control over their information diets [see also @iyengar2009red]. While people can access an ever-growing set of news outlets of varying quality, we only have a limited understanding how these systemic changes in information channels moderate the effectiveness of corrective information itself. Past research mostly focused on the effect of different _types_ of misinformation corrections. This study contributes to the literature by shifting the focus to the question of _how_ and _from where_ corrective information reaches people.


# Why misinformation corrections (often) fail

To the extent that people rely on inaccurate factual beliefs to form their opinions, misinformation can severely impede democratic representation by inducing collective preferences that systematically diverge from a more informed public [@kuklinski2000misinformation]. For instance, earlier studies focusing on aggregate opinion estimated that increasing individual information levels results in altered preferences of the electorate [e.g., @bartels1996uninformed; @althaus1998information]. Experimental studies examining change in individual attitudes, however, only found scant evidence for information treatments impacting peoples underlying opinions [see @flynn2017nature for an overview].

Focusing on misinformation in the context of immigration, @hopkins2019muted conducted multiple survey experiments informing participants about the size of the foreign-born population in the US---a statistic that is systematically overestimated by people in the absence of corrective information. In other words, many Americans are systematically misinformed, and this misinformation is associated with attitudes towards minority groups. Across seven separate survey experiments, the authors find that "accurate information does little to affect attitudes toward immigration, even though it does reduce the perceived size of the foreign-born population. [...] Misperceptions about the size of minority groups may be a consequence, rather than a cause, of attitudes toward those groups" [@hopkins2019muted, 315]. The authors therefore suggest that attitudes towards immigration resist change because they are grounded in more fundamental predispositions that are independent of the factual premise [see also @hainmueller2014public]. 

In sum, changing people's minds by providing corrective information is far from easy---especially when it comes to deeply held beliefs that are connected to people's identities [@nyhan2019taking]. However, this does not imply that new facts are bound to have no attitudinal consequences whatsoever. Although people engage in motivated reasoning and resist counter-attitudinal evidence [@Taber2006], there is some evidence that they are not completely immune to it [@redlawsk2010affective]. Before turning our discussion to a potential mechanism that may facilitate such attitude change, we need to begin by developing a clear conceptualization of different types of updating that may result from exposure to corrective information.


## Differentiating factual beliefs, interpretations, and opinions

Building on a framework developed in @gaines2007same, we define factual *beliefs* as assessments of the state of the world that are, at least in principle, intersubjectively observable and can therefore be either true or false. For example, the statement "Immigrant-owned businesses employed almost 8 million American workers in 2019" describes a factual belief that is objectively verifiable and, importantly, devoid of evaluative components. As we will further discuss below, it turns out that people are systematically misinformed about the number of workers employed by immigrant-owned businesses in the sense that they consistently underestimate this statistic. Corrective information in this example would simply consist of an accurate estimate, which, given previous evidence using similar designs [e.g., @hopkins2019muted], should be fairly effective in correcting factual misperceptions.

Incorrect factual beliefs only impede democratic representation to the extent that they affect people's preferences [@kuklinski2000misinformation]. As such, it seems insufficient to consider the effect of misinformation corrections on factual beliefs alone. Rather, we need to examine how they influence subsequent evaluations. We define the step of adding immediate evaluative components to factual beliefs as *interpretations*. Continuing our previous example, a possible interpretation could be the following statement: "Immigrants improve the U.S. economy by creating additional jobs." This statement is still grounded in knowable facts such as the number of people employed by immigrant-owned businesses, but it contains evaluative components that are driven by implicit premises about potential economic "downsides" of immigration. Holding everything else constant, corrective information about the actual number of workers employed by immigrant-owned businesses should lead to a more positive assessment of the economic benefits of immigration. However, there is substantial leeway for people to interpret the same facts differently depending on their political predispositions [e.g., @gaines2007same].

Lastly, we define *opinions* as evaluative judgments that are formed about the state of the world, but that are not necessarily based on verifiable facts. An example of an opinion in our context would be the statement "The number of immigrants from foreign countries should be increased." Of course, this statement might be informed by objective facts about the economic impact of immigrant-owned business, but it certainly does not have to be. As such, corrective information can only be expected to have limited effects on opinions as these are largely driven by more fundamental predispositions.

How does this conceptualization of beliefs, interpretations, and opinions help us understand potential impact of corrective information? @gaines2007same uses this framework to differentiate four different types of updating as a response to a changing state of the world:

1. **Complete Updating:** \hspace{0.5em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
2. **Fact Avoidance:** \hspace{2.4em} reality **| |** beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
3. **Meaning Avoidance:** \hspace{0.4em} reality $\rightarrow$ beliefs **| |** interpretations $\rightarrow$ opinions
4. **Opinion Disconnect:** \hspace{0.85em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations **| |** opinions

Under complete updating, new factual information directly shapes beliefs about the state of the world, which in turn affects relevant interpretations, and ultimately results in opinion change. Consequently, incomplete updating despite new information could be due to a lack of belief updating (fact avoidance), interpretations that resist altered beliefs (meaning avoidance), or opinions driven by predispositions alone (opinion disconnect). Within this framework and considering the arguments outlined above, we can state the first hypothesis regarding the effectiveness of misinformation as follows:

> *Hypothesis 1:* Misinformation corrections have stronger effects on people's factual **beliefs** than their related **interpretations** or **opinions**.

In other words, while complete fact avoidance is relatively rare when people encounter corrective information, meaning avoidance and (especially) opinion disconnect is more common. Unfortunately, since few studies on misinformation corrections rely on an explicit distinction between these types of incomplete updating, surprisingly little is known about the determinants that make one type more likely than another. In the following section, we are going to argue that the source of corrective information is a crucial moderator in this context.


## The role of selective exposure and source credibility

Despite the fact that there is burgeoning interdisciplinary research on misinformation corrections, most experimental studies in this area rely on relatively simple designs that randomly assign different types of informational treatments to participants. While such designs have certain advantages such as straightforward causal identification, they essentially ignore a crucial aspect of our media environment: people's discretion over their individual media diet and the information they decide to access. There are notable examples of research in related areas that directly address selective exposure as part of their experimental designs---such as recent work on media hostility [@arceneaux2012polarized], persuasion [@benedictis2019persuading], and political knowledge [@leeper2020raising]. To our knowledge, however, no experimental study on misinformation corrections to date takes similar steps to account for endogenous media choice. This is surprising since individual media environments are becoming increasingly diverse and polarized [see @stroud2017selective for an overview], which makes it relatively easy for people to avoid counter-attitudinal corrective information [@guess2020exposure]. As such, prior studies do not allow us to estimate a key quantity of interest: the effect of misinformation corrections among people who would have chosen to access corrections in the first place [@benedictis2019persuading].

Considering our differentiation between beliefs, interpretations, and opinions, we argue that selective exposure is a key mechanism that influences whether misinformation corrections ultimately result in complete updating, opinion disconnect, meaning avoidance, or even fact avoidance. People who are exposed to information that they themselves did not seek out---as it usually happens in most misinformation experiments---might still be open to updating their factual beliefs. However, they may be less likely to incorporate the new information in their interpretations and subsequent opinions than if they voluntarily chose to access the information.This expectation is grounded in work by Stroud et al. (2019), who develop a theoretical explanation for why the circumstances of exposure to information--forced or by choice--might vary. The authors find that the mere act of being forced to see content increases reactance and enhances strategies to reduce cognitive dissonance, even among those viewing preferred content. These reactions are lower when participants select the content themselves. We therefore have the following expectation regarding the effect of the ability to choose information sources:

> *Hypothesis 2:* Misinformation corrections have stronger effects if people are able to **choose** their information source. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

In other words, we expect that meaning avoidance and opinion disconnect are less common if people have discretion over what information to access. This relationship may be driven by two potential explanations. On the one hand, those participants who are allowed to choose their information sources experience less reactance--negative reactions to a choice that has been taken away--and cognitive dissonance--which leads them to hold message-consistant attitudes--than those participants who experience constraints on their freedom to choose information (per Stroud et al. 2019).

A second and closely related mechanism is source credibility driven by people's media preferences. While previous research on misinformation corrections has largely ignored the question of selective exposure, multiple studies examined the role of source credibility. For example, @guillory2013correcting found that corrective information is especially effective if it comes from a source perceived to be trustworthy. Similarly, @berinsky2017rumors presented evidence that the rebuttal of rumors in the context of health care reform were more effective when politicians issuing the correction act counter to their personal and political interests. Other studies, however, indicate that the source is less consequential for the effectiveness of corrections [e.g., @swire2017processing]. Notwithstanding, we expect that people's media preferences should influence the receptivity to corrective information:

> *Hypothesis 3:* Misinformation corrections have stronger effects if the information source is **consistent** with people's media preferences. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

This hypothesis represents the classic source credibility argument since people should perceive their preferred information sources as more trustworthy. As such, it can be expected that meaning avoidance and opinion disconnect is less common if people are exposed to information provided by a news organization they view favorably.
<!--add some discussion of why this varies for opinions/interpretations vs. beliefs?-->

A skeptical reader might argue that *Hypothesis 2* and *Hypothesis 3* are essentially two sides of the same coin if discretion to choose an information source leads to a higher likelihood of consistency between particpants' underlying preferences and the information source than if sources are randomly assigned. Indeed, studies that find differences between forced and selective exposure (CITES) often explain these differences as a function of participants' preferences for media content. 

In order to tease out the effect of the circumstances of exposure (assigned vs. free choice) from the effect of source credibility, we compare consistent-consistent to inconsistent-inconsistent. <!--need to word this in a better way....-->If the mechanism is source credibility, we should find that those who seek out (in)consistent sources are no more likely to change their attitudes than those who are assigned to them.

We contend that it is ultimately an empirical question whether the effect of the ability to choose media sources on opinion/attitude change is solely driven by media preferences and related source credibility. Our empirical analyses---to which we are going to turn next---provide at least some evidence that this may not be the case.

# Research Design
With a sample of 600 participants recruited via Amazon's Mechanical Turk, this study aims to explore how the way people access corrective information influences its potential to change related beliefs, interpretations, and opinions. Our experimental framework builds on the Preference-Incorporating Choice and Assignment (PICA) design [@benedictis2019persuading; @knox2019design], where one group of participants is randomly assigned to information treatments from different sources while another group is allowed to freely choose which source to access. Such a setup allows us to observe the moderating effect of individual media diet and the information they decide to access.

<!-- Add discussion of specific advantages of this design -->

Figure \ref{fig:flow} displays an overview of the experimental design. Participants are first asked to answer a set of pre-treatment questions regarding their media preferences and their attitudes towards immigration. Subsequently, they are randomly assigned to a free choice treatment condition, a forced exposure treatment condition, or a control group. 

```{r flow, fig.cap="\\label{fig:flow}Survey flow and overview of the experimental design. See Appendix for further details such as question wording and information treatments."}
knitr::include_graphics("../prereg/Lab-Graphic.jpg")
```

Participants in the free choice condition are asked to choose whether they want to see a recent breaking news tweet from either Fox News or MSNBC:

> In the following section, we are going to show you a random tweet drawn from the accounts of [two/several] large news organizations. **You can choose from which Twitter account the random tweet will be drawn.** Afterwards, we are going to ask you some questions about the content of the news story.

Participants in the forced exposure condition read almost the same message, the only difference being that it omitted the bold sentence telling them that they can choose from which Twitter account the random tweet will be drawn. Depending on their preference (in the free choice condition) or random assignment (in the forced exposure condition), participants are then shown one of the following tweets displayed in Figure \ref{fig:tweets}, which links to a news story focusing on immigrant-owned businesses in the U.S. It is important to note that both tweets contain exactly the same information, so regardless of which news organization participants chose (or were assigned to), the information itself is held constant.

```{r tweets, fig.show="hold", out.width="50%", fig.cap="\\label{fig:tweets}Information treatment on the size of immigrant-owned businesses in the U.S. from two different sources (Fox News or MSNBC)."}
knitr::include_graphics(c("../material/tweets/fox_popular.png", "../material/tweets/msnbc_popular.png"))
```

After viewing one of the tweets, participants are asked to read the corresponding article. As before, the content of the news article is held constant across sources in either condition.[^1] Compared to previous implementations of the PICA framework where the content was not held constant across sources [@benedictis2019persuading; @knox2019design], our design allows us to directly compare the effects of free choice and forced exposure by ensuring that differences between treatment groups are not the result of the structure, content, or tone of different stories. Finally, participants who are randomly assigned to the control group skip the tweet and article entirely and move directly from the pre-treatment battery to the post-treatment outcome measures.

[^1]: See Appendix for full article.

In our analysis, we consider five different outcome measures that correspond to beliefs, interpretations, and opinions related to the economic impact of legal immigration in the U.S. The full question overview is displayed in Table \ref{tab:outcomes}. Two items targeting factual *beliefs* directly ask for statistics regarding the number of workers employed by immigrant-owned businesses as well as the total amount of sales revenue of immigrant-owned businesses. Both questions offer five response options (one of which is accurate) and the correct information is mentioned in the tweet as well as the news article.

In order to measure *interpretations* consistent with the theoretical conceptualization discussed above, we asked respondents two additional questions about whether they believe that immigrants add to the economy by creating additional jobs and whether they contribute more by paying taxes than they take out by using health and social services. Responses for both items are measured on an 11-point scale.

Lastly, we measure *opinions* by asking for the participants' general preference regarding the number of immigrants from foreign countries who are permitted to come to the U.S. Responses for this item are measured on a 5-point scale ranging from "increased a lot" to "decreased a lot."

```{r outcomes}
tribble(
  ~Belief, ~Interpretation, ~Opinion,
  "Across the United States, how many workers--immigrant and US-born--do you think are employed by immigrant-owned businesses?",
  "On average, would you say that people who come to live here from other countries will take jobs away from people already here or add to the economy by creating additional jobs?",
  "Do you think the number of immigrants from foreign countries who are permitted to come to the United States to live should be [increased/left the same/decreased]", "", "", "",
  "Taking your best guess, what was the total amount of sales revenue of immigrant-owned businesses in the last year?",
  "Most people who come to live in the U.S. work and pay taxes. They also use health and social services. On balance, do you think people who come here take out more than they put in or put in more than they take out?",
  ""
) %>%
  knitr::kable("latex", 
               caption = "\\label{tab:outcomes}Overview of outcome variables measuring beliefs, interpretation, and opinions related to the economic impact of legal immigration in the U.S.",
               booktabs = TRUE) %>%
  kableExtra::column_spec(1, width = "4cm") %>%
  kableExtra::column_spec(2, width = "6cm") %>%
  kableExtra::column_spec(3, width = "5cm")
```

# Results 

Compared to previous studies, the outcome measures described above allow for a much more fine-grained differentiation of possible types of (incomplete) updating as a response to misinformation corrections. Now, we are going to examine the role of media preferences and the ability to choose information sources as predictors of changes in beliefs, interpretations, and opinions.


## Free Choice Enables Opinion Change

As a first step, we examine the average treatment effects of the forced exposure and free choice conditions for each of the five outcome measures compared to the control group that did not have access to the tweet or news article. For each dependent variable, we estimate a linear regression with two treatment indicators (the control condition is the reference category) while controlling for a set of pre-treatment covariates and sociodemographic characteristics to increase statistical power [e.g., @bowers2011making; @clifford2020increasing]. Figure \ref{fig:m1} focuses on the estimated effect of the treatment indicators and the full regression table including controls can be found in the Appendix. Since the measures of factual beliefs are dichotomous, the first set of coefficients examining belief change can be interpreted as linear probability models, whereas the remaining coefficients can be interpreted as treatment effects where the (quasi-)continuous outcome variable was rescaled to range from zero to one.

```{r m1, fig.height=2, fig.width=7, fig.cap="\\label{fig:m1}Treatment effects of forced exposure and free choice manipulation (vs. control). Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 95\\% confidence intervals based on robust standard errors. Full model results presented in the appendix."}
p1
```

Compared to the control condition, the proportion of correct responses regarding the employment and total value of sales by immigrant-owned businesses is about 20 to 30 percentage points higher among participants who read the tweet and news story. This is a substantively large effect and it is illustrative of the fact that participants systematically underestimated the economic contributions of immigrant-owned business if they were not given any additional information.

Turning to the effect of corrective information on interpretations, we observe smaller, but still statistically significant treatment effects. After reading the tweet and news story, participants provided a more favorable assessment regarding the number of jobs created by immigrants as well as the relative size of their tax contributions. As for beliefs, this effect is significant for both the forced exposure and the free choice conditions.

Lastly, treatment effects are largely diminished when examining opinion change as a response to forced exposure to corrective information, which is consistent with previous experimental evidence [e.g., @hopkins2019muted]. <!--add some discussion from Stroud et al 2019 here? --> Interestingly, however, we do observe a small but statistically significant effect of the free choice condition on people's opinion toward legal immigration in the U.S.

The finding that estimated treatment effects are smaller for interpretations and opinions than for beliefs strongly supports Hypothesis 1. In addition, differences between the forced exposure and free choice conditions across outcomes appear limited at best. Updating beliefs and interpretations as a response to misinformation corrections is relatively common and independent of how people gain access to them. Only if people are allowed to choose their information source, however, do we observe that they change their opinions about the issue. While this is at least suggestive evidence that selective exposure and discretion over media diets is a potentially important factor facilitating opinion change, it should be noted that the difference between both treatment effects themselves is not statistically significant [@gelman2006difference]. Overall, however, these results lend at least some support to Hypothesis 2. The following section will explore the role of media preferences and source consistency in this context. <!--but also conditions of exposure, right?-->


## Opinion Change is Driven by Voluntary Exposure to Inconsistent Sources

At the beginning of our survey experiment, we included a battery of questions regarding people's usual media diet. Among other items, participants were asked the following question:

> On average, how often do you watch political news on the following TV channels (including online content)?

The question was followed by a list of five news outlets including Fox News and MSNBC.<!--need more descriptives here (ex. # of people in each category).--> Based on this item, we can distinguish whether participants in the treatment conditions were exposed to an information source that is consistent or inconsistent with their usual media preferences (if they usually prefer to watch more Fox News than MSNBC and vice versa), or if the information source is neutral (if they prefer neither Fox News or MSNBC as part of their usual media diet). Figure \ref{fig:m2} repeats the previous analysis examining treatment effects on beliefs, interpretations, and opinions---but now differentiating participants in the forced exposure and free choice conditions by source consistency.

```{r m2, fig.height=3.5, fig.width=7.1, fig.cap="\\label{fig:m2}Treatment effects of forced exposure and free choice manipulation (vs. control) conditional on consistency between media preference and information source. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 95\\% confidence intervals based on robust standard errors. Full model results presented in the appendix."}
p2
```

Focusing first on beliefs and interpretations as outcomes, we observe slightly larger treatment effects for participants who were exposed to an information source that is consistent with their usual media diet---a pattern that holds in the forced exposure as well as the free choice condition. In fact, in three out of four analyses, the information treatment had no statistically significant effect on people's interpretations regarding the economic benefits of legal immigration if it came from an inconsistent source, whereas exposure to a consistent source was always associated with more favorable interpretations. This result is largely consistent with our third hypothesis that misinformation corrections will have stronger effects if the information source is consistent with respondents' media preferences. 

Interestingly, the pattern for opinion change as a response to the news story appears to be reversed. To the extent that the positive treatment effect of the free choice condition on opinions reported in Figure \ref{fig:m1} is driven by people's tendency to seek out consistent sources, we would expect a similar effect when focusing on forced exposure to consistent sources. This is not the case. Regardless of whether participants were given a news source that is consistent with their usual media diet, the information treatment in the forced exposure condition had no effect on subsequent opinions regarding the desired level of immigration in the U.S. In the free choice condition, on the other hand, we do find evidence for opinion change compared to control condition. Surprisingly, however, it is exposure to *inconsistent* sources in the free choice condition that ultimately results in significant opinion change.

To further corroborate this finding, we now directly compare the effect of voluntary and involuntary exposure to inconsistent sources. Specifically, we reduce the sample to include only participants who were exposed to a news source that was inconsistent with their usual media diet. We then run regressions using the same specifications as before, now only including a single treatment indicator for the free choice condition. Note that since this specification omits the control group and instead uses forced exposure to inconsistent sources as the reference category, the coefficients can be interpreted as the differences in treatment effects between the free choice and forced exposure condition. The results are displayed in Figure \ref{fig:m4}.

```{r m4, fig.height=2, fig.width=6.5, fig.cap="\\label{fig:m4}Difference in treatment effects of free choice manipulation (vs. forced exposure) conditional on exposure to information source that is inconsistent with media preference. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger treatment effect for voluntary (vs. involuntary) exposure to inconsistent source. 95\\% confidence intervals based on robust standard errors. Full model results presented in the appendix."}
p4
```

Conditional on exposure to an inconsistent source, there are no clear differences in treatment effects on beliefs and related interpretations. However, participants who were exposed to inconsistent sources in the free choice condition reported more favorable opinions towards immigrants than participants who were exposed to inconsistent sources in the forced exposure condition. This finding is quite remarkable considering the fact that regardless of the news organization, the actual content of the tweet and article was constant across all treatments.

In sum, changing people's minds by giving them free choice over their media diet is not driven by the ability to choose consistent news sources. On the contrary, only participants who voluntarily accessed information from an inconsistent source reported significantly different opinions than the control group. In the next section, we explore why this change occurs.
<!--JJ comments: in this section, need to say more about why consistent sources are more persuasive for changing interpretations but inconsistent sources are more persuasive when it comes to changing opinions.-->
## Motivation Or Ambivalence? 

Much like other studies of information seeking behavior, we find there are subjects who voluntarily seek out information from sources that are counter to our expectations [CITES]. <!--go deeper into this literature? ex. They do this for x, y, z reasons... e.g., accuracy motivations/weaker directional motivations? see Leeper and Slothuus 2014; Pietryka 2016-->
We find that these subjects are also more likely to exhibit opinion change/are more receptive to corrective information (recap findings from previous section). We suspect there are two potential explanations at play here: On the one hand, these information-seeking motivations are potential indicators of receptivity to new information and thus result in a greater likelihood of updating. [STILL NEED SOME LITERATURE HERE.]

It could also be that those viewing information from what we deem as 'inconsistent' with their preferred outlets are simply more ambivalent/have weaker attitudes about the issue.<!--or politics in general --> 

in order to shed light on the underlying mechanism at play, we provide a secondary analysis leveraging open-ended responses...[what should we find if it's option 1? what do the results look like if it's the latter mechanism at play?]
<!--add analysis of open-ended responses. -->

# Discussion and Conclusion

The apparent pervasiveness of misinformation across a wide range of political issues is exacerbated by an increasingly polarized media environment where people have unprecedented access to a wide variety of media sources. When it comes to the effectiveness of corrective interventions, revising people's factual *beliefs* is relatively easy, while changing their underlying *opinions* is hard. Yet, previous research in this context neglected the role of selective exposure and endogenous information search as a determinant of the potential attitudinal impact of corrective information.

Our study fills this gap in the literature by employing an experimental design that allows a subset of participants to choose their information source. Holding the actual content constant, we find that the ability to choose news sources facilitates opinion change. However, the effect of people's discretion over their information intake is not driven by their tendency to access sources that are consistent with their usual media diet. Rather, it is the voluntary exposure to inconsistent sources that results in opinion change. Accordingly, encouraging people to voluntarily access alternative sources may be a more effective strategy to combat misinformation than providing fact-checks alone.

Of course, our findings are not without limitations. Most importantly, it is worth noting that conditioning on (in)consistent exposure in the free choice condition makes it difficult to provide a clear causal interpretation of the effects. While our analyses control for political predispositions and pre-treatment immigration attitudes, we cannot fully rule out the possibility that people who self-selected into exposure to an inconsistent source had substantively different attitudes irrespective of the treatment instead of being more receptive to the corrective information<!--they also could be different in how they process new information-->. The fact that we do observe significant treatment effects for the free choice condition (and not for the forced exposure condition) across the entire sample somewhat alleviates this concern, since this overall relationship cannot be explained purely by self-selection into inconsistent exposure. As such, it seems more likely that the patterns are driven by people's underlying openness to consider alternative views than by differences in baseline attitudes. Ultimately, while more work is necessary to corroborate this conclusion, we find at least suggestive evidence that discretion over information sources facilitates opinion change in response to corrective information. In order to further substantiate these findings, we are planning a pre-registered replication of this study focusing on a different policy area and using a larger sample size.

<!-- add discussion of literature on accuracy motivation and related predispositions to be open-minded -->
<!-- mention small sample size in last analysis as additional limitation -->

\clearpage


# References
