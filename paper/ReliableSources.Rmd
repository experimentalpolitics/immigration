---
title: "Reliable Sources?"
#^[Presented at the 2020 Annual Meeting of the International Society for Political Psychology. We thank Jennifer Jerit, Emmy Lindstam, and Pirmin StÃ¶ckle for helpful comments on previous versions of this manuscript.]"
subtitle: >
  Correcting Misinformation in Polarized Media Environments \vspace{10em}
#author:
#  - "Patrick W. Kraft^[Corresponding author, kraftp@uwm.edu]"
#  - Nicholas R. Davis
#  - Taraleigh Davis
#  - Amanda Heideman
#  - Jason T. Neumeyer
#  - Shin Young Park
#date: |
#  |
#  | University of Wisconsin-Milwaukee 
#  |
#  | \today
#  |
#  |
abstract: >-
  \noindent Providing corrective information can reduce factual misperceptions among the public but it tends to have little effect on people's underlying attitudes. Our study examines how the impact of misinformation corrections is moderated by media choice. In our experiment, participants are asked to read a news article published by Fox News or MSNBC, each highlighting the positive economic impact of legal immigration in the United States. While the news content is held constant, our treatment manipulates whether participants are allowed to freely choose a media outlet or are randomly assigned. Our results demonstrate the importance of people's ability to choose: While factual misperceptions are easily corrected regardless of how people gained access to information, subsequent opinion change is conditional on people's prior willingness to seek out alternative sources. As such, encouraging people to broaden their media diet may be more effective to combat misinformation than disseminating fact-checks alone.
#Various pressing issues at the center of today's politics---such as immigration, climate change, or the recent coronavirus pandemic---are imbued with misinformation. While a growing body of research demonstrates how corrective information can mitigate factual misperceptions among the public, these interventions tend to have little to no effect on people's underlying attitudes. This study examines how the impact of corrective information on beliefs and attitudes is moderated by media choice. In our survey experiment, participants are asked to read a news article published by Fox News or MSNBC, each highlighting the positive economic impact of legal immigration in the United States. While the news content is held constant across sources, our treatment manipulates whether participants are allowed to freely choose a media outlet or are randomly assigned to one of them. Our results illustrate how people's media choice moderates the effectiveness of corrective information. While factual misperceptions are easily corrected regardless of how people gained access to the information, subsequent opinion change is conditional on people's prior willingness to seek out alternative sources. As such, encouraging people to broaden their media diet may be more effective to combat misinformation than disseminating fact-checks alone.
reference-section-title: References
bibliography: '../../bibliography/Lab.bib'
fontsize: 12pt
geometry: margin=1in
linestretch: 1.5
output: 
  pdf_document:
    number_sections: false
    template: null
    fig_caption: yes
header-includes:
  \renewcommand{\familydefault}{\sfdefault}
  \usepackage{float}
  \usepackage{censor}
  \floatplacement{figure}{H}
  \parskip=0pt
  \parindent=20pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r code}
## Load packages, data, analyses
source("../code/02-analysis.R")
source("../code/03-liwc.R")
```

<!-- Page count: 6183 -->

\thispagestyle{empty}
\clearpage
\setcounter{page}{1}
\doublespace

\noindent Citizens in western democracies hold wide-ranging and systematic misperceptions about immigrants to their home countries. For example, people usually overestimate the total number of immigrants or the proportion of immigrants that are dependent on social welfare [@alesina2019immigration]. These factual misperceptions are reinforced by the news media and, in turn, can foster biased attitudes and stereotypes [@Wright2020]. Given the extensive spread of misinformation, researchers from various disciplines started examining how corrective information may affect people's underlying attitudes [see @flynn2017nature for a review]. However, while corrective information may alleviate some factual misperceptions, it rarely affects people's underlying attitudes [@hopkins2019muted; @swire2020they].

A possible explanation for this apparent disconnect could be that factual information is simply irrelevant for attitude formation and---if anything---serves as a mere justification for people to rationalize their existing predispositions towards immigrant populations. Yet, the extent to which people engage in such motivated reasoning is not without limits; they update their prior beliefs after reaching a "tipping point" of counter-attitudinal information [@redlawsk2010affective]. Furthermore, recent studies on immigration attitudes demonstrate the persuasiveness of certain interventions such as canvassing [@kalla2020reducing].

Why do researchers frequently fail to find evidence of attitude change after providing respondents with corrective information? We argue that most experimental designs in this area are inconclusive because they omit a crucial mechanism: people's discretion over whether to engage with a given information source or not. Specifically, studies usually employ simple random assignment of informational treatments without considering people's selective exposure. Unfortunately, such a set-up does not allow us to estimate the effect of misinformation corrections among people who would have chosen to access the information in the first place [@benedictis2019persuading; @knox2019design]. Furthermore, denying people the freedom to select sources can increase reactance and counter-arguing and therefore render corrections less effective [@stroud2019consequences].

We address these shortcomings by implementing an experimental design that varies both the source of misinformation corrections, as well as the process through which people access the information. Specifically, we conduct an online survey experiment on the effectiveness of corrective information about immigration. Depending on the experimental condition, participants are either able to freely choose--or are assigned to--an article published by different news channels (Fox News vs. MSNBC), which discusses the economic impact of legal immigration. Crucially, our design allows us to differentiate how the information treatment impacts factual beliefs, how they are interpreted, as well as broader attitudes towards immigration. The results indicate that while the correction of factual misperceptions does not depend on media choice, subsequent attitude change is conditional on people's willingness to voluntarily seek out alternative sources.

Taking into account endogenous information search in studies of misinformation corrections is crucial in our rapidly changing media environment where people have unprecedented control over their information diets [@iyengar2009red]. While people can access an ever-growing set of news outlets of varying quality, we only have a limited understanding how these systemic changes in information channels moderate the effectiveness of corrective information itself. Past research mostly focused on the effect of different _types_ of misinformation corrections. This study contributes to the literature by shifting the focus to the question of _how_ and _from where_ corrective information reaches people.


# Why misinformation corrections (often) fail

To the extent that people rely on inaccurate factual beliefs to form their opinions, misinformation can severely impede democratic representation by inducing collective preferences that systematically diverge from a more informed public [@kuklinski2000misinformation]. For instance, earlier studies focusing on aggregate opinion estimated that increasing individual information levels results in altered preferences of the electorate [e.g., @bartels1996uninformed; @althaus1998information]. Experimental studies examining individual attitude change, however, only found scant evidence for information treatments impacting people's underlying opinions [see @flynn2017nature for an overview].

Focusing on misinformation in the context of immigration, @hopkins2019muted conducted multiple survey experiments informing participants about the size of the foreign-born population in the US---a statistic that is systematically overestimated by people in the absence of corrective information. In other words, many Americans are systematically misinformed, and this misinformation is associated with attitudes towards minority groups. Furthermore, "accurate information does little to affect attitudes toward immigration, even though it does reduce the perceived size of the foreign-born population. [...] Misperceptions about the size of minority groups may be a consequence, rather than a cause, of attitudes toward those groups" [@hopkins2019muted, 315]. The authors therefore suggest that attitudes towards immigration resist change because they are grounded in more fundamental predispositions that are independent of the factual premise [see also @hainmueller2014public]. 

In sum, changing people's minds by providing corrective information is far from easy---especially when it comes to deeply held beliefs that are connected to people's identities [@nyhan2019taking]. However, this does not imply that new facts are bound to have no attitudinal consequences whatsoever. Although people engage in motivated reasoning and resist counter-attitudinal evidence [@Taber2006], there is some evidence that they are not completely immune to it [@redlawsk2010affective]. Before turning our discussion to potential mechanisms that may facilitate such attitude change, we need to develop a clear conceptualization of different types of updating that may result from exposure to corrective information.


## Differentiating factual beliefs, interpretations, and opinions

Building on a framework developed in @gaines2007same, we define factual *beliefs* as assessments of the state of the world that are, at least in principle, intersubjectively observable and can therefore be either true or false. For example, the statement "Immigrant-owned businesses employed almost 8 million American workers in 2019" describes a factual belief that is objectively verifiable and, importantly, devoid of evaluative components. As we discuss below, people are systematically misinformed about the number of workers employed by immigrant-owned businesses in the sense that they consistently underestimate this statistic. Corrective information in this example would simply consist of an accurate estimate, which, given previous evidence using similar designs [e.g., @hopkins2019muted], should be effective in correcting factual misperceptions.

Incorrect factual beliefs only impede democratic representation to the extent that they affect people's preferences [@kuklinski2000misinformation]. As such, it would be insufficient to consider the effect of misinformation corrections on factual beliefs alone. Rather, we need to examine how they influence subsequent evaluations. We define the step of adding immediate evaluative components to factual beliefs as *interpretations*. Continuing our previous example, a possible interpretation could be the following statement: "Immigrants improve the U.S. economy by creating additional jobs." This statement is still grounded in knowable facts such as the number of people employed by immigrant-owned businesses, but it contains evaluative components that are driven by implicit premises about potential economic "downsides" of immigration. Holding everything else constant, corrective information about the actual number of workers employed by immigrant-owned businesses should lead to a more positive assessment of the economic benefits of immigration. However, there is substantial leeway for people to interpret the same facts differently depending on their political predispositions [e.g., @gaines2007same].

Lastly, we define *opinions* as evaluative judgments that are formed about the state of the world, but that are not necessarily based on verifiable facts. An example of an opinion in our context would be the statement "The number of immigrants from foreign countries should be increased." Of course, this statement might be informed by objective facts about the economic impact of immigrant-owned business, but it does not necessarily have to be. As such, corrective information can only be expected to have limited effects on opinions as these are largely driven by more fundamental predispositions.

How does this conceptualization of beliefs, interpretations, and opinions help us understand potential impact of corrective information? @gaines2007same uses this framework to differentiate four different types of updating as a response to a changing state of the world:

\singlespace

1. **Complete Updating:** \hspace{0.5em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
2. **Fact Avoidance:** \hspace{2.4em} reality **| |** beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
3. **Meaning Avoidance:** \hspace{0.4em} reality $\rightarrow$ beliefs **| |** interpretations $\rightarrow$ opinions
4. **Opinion Disconnect:** \hspace{0.4em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations **| |** opinions

\vspace{1em}\doublespace

\noindent Under complete updating, new factual information directly shapes beliefs about the state of the world, which in turn affects relevant interpretations, and ultimately results in opinion change. Consequently, incomplete updating despite new information could be due to a lack of belief updating (fact avoidance), interpretations that resist altered beliefs (meaning avoidance), or opinions driven by predispositions alone (opinion disconnect). Within this framework and considering the arguments outlined above, we therefore state our first hypothesis as follows:

\singlespace

> *Hypothesis 1:* Misinformation corrections have stronger effects on people's factual **beliefs** than their related **interpretations** or **opinions**.

\vspace{1em}\doublespace

\noindent Consistent with past research, we expect fact avoidance to be relatively rare when people encounter corrective information. Meaning avoidance and (especially) opinion disconnect, however, may be considerably more common. Unfortunately, since few studies on misinformation corrections rely on an explicit distinction between these types of incomplete updating, surprisingly little is known about the determinants that make one type more likely than another. In the following section, we argue that the source of corrective information is a crucial moderator in this context.


## The role of media choice and source credibility

Notwithstanding the burgeoning interdisciplinary research on misinformation corrections, most experimental studies in this area rely on relatively simple designs that randomly assign different types of informational treatments to participants. While such designs have certain advantages such as straightforward causal identification, they ignore a crucial aspect of our media environment: people's discretion over their individual media diet and the information they decide to access. There are notable examples of research in related areas that directly address selective exposure as part of their experimental designs---such as recent work on media hostility [@arceneaux2012polarized], persuasion [@benedictis2019persuading], and political knowledge [@leeper2020raising]. To our knowledge, however, no experimental study on misinformation corrections to date takes similar steps to account for endogenous media choice. This is surprising since individual media environments are becoming increasingly diverse and polarized [@stroud2010polarization; @stroud2011niche], which makes it relatively easy for people to avoid counter-attitudinal corrective information [@guess2020exposure]. As such, prior studies do not allow us to estimate a key quantity of interest: the effect of misinformation corrections among people who would have chosen to access corrections in the first place [@benedictis2019persuading].

Building on our differentiation between beliefs, interpretations, and opinions, we argue that media choice is a key mechanism that influences whether misinformation corrections ultimately result in complete updating, opinion disconnect, meaning avoidance, or even fact avoidance. Prior studies suggest that people are willing to update their factual *beliefs* in response to corrective information regardless of whether they were able to choose a source. However, the reason that they seem less inclined to incorporate corrections in their *interpretations* and subsequent *opinions* may be because they are exposed to information that they did not seek out themselves---as it usually happens in most misinformation experiments. This argument is grounded in work by @stroud2019consequences, who develop a theoretical framework that explains how varying circumstances of information exposure---i.e., whether it was accessed voluntarily or not---impact individual responses to said information. Specifically, being forced to view content without freedom of choice generates reactance (i.e., negative affect and counter-arguing) and cognitive dissonance, even among those who are assigned to preferred content [@stroud2019consequences]. Thus, we can formulate the following expectation regarding the impact of being able to choose information sources:

\singlespace

> *Hypothesis 2:* Misinformation corrections have stronger effects if people are able to **choose** their information source. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

\vspace{1em}\doublespace

\noindent In sum, we expect that meaning avoidance and opinion disconnect are less common if people have discretion over what information to access. For instance, a large component of news articles consists of contextualizing information and thereby providing suitable interpretations of the underlying facts. The initial ability to select a news source may make people more willing to adopt the interpretations provided therein along with the factual information itself.

In addition to the hypothesized effect of people's ability to choose in and of itself, we consider a closely related mechanism centered on the impact of a given source itself. Although previous research on misinformation corrections has largely ignored the potential impact of people's freedom to select content, what has been studied extensively is the effect of the perceived credibility of a given source. For example, @guillory2013correcting find that corrective information is especially effective if it comes from a source perceived to be trustworthy. Similarly, @berinsky2017rumors presents evidence that the rebuttal of rumors in the context of health care reform was more effective when politicians issuing the correction act counter to their personal and political interests. Other studies, however, indicate that the source is less consequential for the effectiveness of corrections [e.g., @swire2017processing]. Notwithstanding, we expect that people's media preferences should influence the receptivity to corrective information:

\singlespace

> *Hypothesis 3:* Misinformation corrections have stronger effects if the information source is **consistent** with people's media preferences. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

\vspace{1em}\doublespace

\noindent This hypothesis follows directly from the aforementioned arguments surrounding source credibility since people should perceive their preferred media outlets as more trustworthy. As such, it can be expected that meaning avoidance and opinion disconnect is less common if people are exposed to information provided by a news organization they view favorably.

It is worth emphasizing that while Hypothesis 2 and 3 are clearly related, they focus on two conceptually distinct mechanisms. The former examines how constraints on people's freedom to choose sources reduce their willingness to incorporate misinformation corrections---regardless of individual predisposition towards a particular source itself. The latter hypothesis, on the other hand, explores the impact of people's perceived credibility of a given source---irrespective of whether it was accessed voluntarily or not. It is ultimately an empirical question to what extent either of these mechanisms enable opinion change in response to corrective information. Distinguishing both, however, has crucial implications for the development of effective interventions to mitigate misinformation. Fortunately, our experimental design---which we are going to turn to next---allows us to disentangle the relative impact of discretion over media sources and individual predispositions towards particular outlets.


# Research Design

The goal of our study is to explore how the way people access corrective information influences its potential to change related beliefs, interpretations, and opinions. Our experimental framework builds on the Preference-Incorporating Choice and Assignment (PICA) design [@benedictis2019persuading; @knox2019design], where one group of participants is randomly assigned to information treatments from different sources while another group is allowed to freely choose which source to access. Figure \ref{fig:flow} displays an overview of our study. The survey begins with a set of pre-treatment questions regarding their media preferences and immigration attitudes. Next, we randomly assign participants to a free choice, forced exposure, or control condition. Participants who receive the free choice treatment are informed that they will be shown a breaking news tweet and they are asked to decide from which media outlet the tweet should be taken (either Fox News or MSNBC). Participants in the forced exposure condition are not offered such a choice but are simply informed that they will be shown a breaking news tweet from a random media outlet.

\singlespace

![\label{fig:flow}Survey flow and overview of the experimental design. See Appendix D for the complete questionnaire.](../prereg/Lab-Graphic.jpg)

```{r flow, fig.cap="\\label{fig:flow}Survey flow and overview of the experimental design. See Appendix D for the complete questionnaire.", eval = FALSE}
knitr::include_graphics("../prereg/Lab-Graphic.jpg")
```

\doublespacing

\noindent Depending on their preference (in the free choice condition) or random assignment (in the forced exposure condition), participants are then shown one of the tweets displayed in Figure \ref{fig:tweets}, which links to a news story focusing on immigrant-owned businesses in the U.S. Importantly, both tweets contain exactly the same information, so regardless of which news organization participants chose (or were assigned to), the information itself is held constant. After viewing one of the tweets, participants are asked to read the corresponding article. As before, the content of the news article is held constant across sources in either condition.[^2]

[^2]: See Appendix D for the full news article.

\singlespace

```{r fig_tweets, fig.show="hold", out.width="50%", fig.cap="\\label{fig:tweets}Information treatment on the size of immigrant-owned businesses in the U.S. from two different sources (Fox News or MSNBC). Participants only view one of the tweets."}
knitr::include_graphics(c("../material/tweets/fox_popular.png", "../material/tweets/msnbc_popular.png"))
```

\doublespace

\noindent Compared to previous implementations of the PICA framework where the content was not held constant across sources [@benedictis2019persuading; @knox2019design], our design allows us to directly compare the effects of free choice and forced exposure while ensuring that differences between treatment groups are not the result of the structure, content, or tone of different stories. Finally, participants who are randomly assigned to the control group skip the tweet and article entirely and move directly from the pre-treatment battery to the outcome measures.

```{r tab_outcomes}
tribble(
  ~Belief, ~Interpretation, ~Opinion,
  "Across the United States, how many workers--immigrant and US-born--do you think are employed by immigrant-owned businesses?",
  "On average, would you say that people who come to live here from other countries will take jobs away from people already here or add to the economy by creating additional jobs?",
  "Do you think the number of immigrants from foreign countries who are permitted to come to the United States to live should be [increased/left the same/decreased]", "", "", "",
  "Taking your best guess, what was the total amount of sales revenue of immigrant-owned businesses in the last year?",
  "Most people who come to live in the U.S. work and pay taxes. They also use health and social services. On balance, do you think people who come here take out more than they put in or put in more than they take out?",
  ""
) %>%
  knitr::kable("latex", 
               caption = "\\label{tab:outcomes}Overview of outcome variables measuring beliefs, interpretation, and opinions related to the economic impact of legal immigration in the U.S.",
               booktabs = TRUE) %>%
  kableExtra::column_spec(1, width = "4cm") %>%
  kableExtra::column_spec(2, width = "6cm") %>%
  kableExtra::column_spec(3, width = "5cm") %>% 
  kableExtra::kable_styling(latex_options =c("hold_position"))
```

For our analysis, we consider five different outcomes that correspond to beliefs, interpretations, and opinions related to the economic impact of legal immigration. The full question overview is displayed in Table \ref{tab:outcomes}. Two items targeting factual *beliefs* directly ask for statistics regarding the number of workers employed by immigrant-owned businesses as well as the total amount of sales revenue of immigrant-owned businesses. Both questions offer five response options,  (one of which is accurate) and the correct information is mentioned in the tweet as well as the news article. In order to measure *interpretations* consistent with the theoretical conceptualization discussed above, we asked respondents two additional questions about whether they believe that immigrants add to the economy by creating additional jobs and whether they contribute more by paying taxes than they take out by using health and social services. Lastly, we measure *opinions* by asking for the participants' overall preference regarding the number of immigrants who should be allowed to move to and live in the United States. Together, these outcome measures allow for a more fine-grained differentiation of possible types of (incomplete) updating than previous studies on the effectiveness of misinformation corrections. In the following section, we are going to leverage this differentiation to examine how the ability to choose information sources moderates their impact on beliefs, interpretations, and opinions.


# Results 

We preregistered our study on \censor{EGAP (Registration ID: 20191119AC)} prior to data collection.[^3] The survey was fielded on Amazon's Mechanical Turk (MTurk) in December 2019 with a sample of 600 respondents. We provide an overview of our sample demographics across treatment conditions as well as balance checks in Appendix A. In general, respondents on MTurk tend to be younger, more liberal, and more educated than the average U.S. population [@huff2015these]. However, while MTurk samples are not representative of the broader U.S. population, they are more diverse than other convenience samples such as college students [@berinsky2012evaluating] and have been shown to be suitable for survey experiments [@krupnikov2014cross]. Indeed, extensive research has demonstrated that results derived from online convenience samples are similar to those obtained from national samples [@clifford2015samples;@coppock2019generalizing;@coppock2019validating].

[^3]: A shortened and de-identified version of the registration and pre-analysis plan is included in Appendix E. 

Recently, however, there has been concern about declining data quality on MTurk---particularly due to the use of virtual private networks (VPNs) to circumvent location restrictions implemented in surveys designed for U.S. participants only [@kennedy2020shape]. Since these fraudulent respondents tend to provide substantially lower-quality responses, we followed current best practices by implementing an automatic script in our survey that identifies and screens out bots and users who mask their true location via VPNs [@winter2019simplified;@waggoner2019detecting]. In addition, we included attention checks at the end of our survey to make sure that respondents read the material carefully. Despite the fact that a small proportion failed our attention checks (less than 10%), we refrained from dropping these respondents in order to avoid post-treatment bias [@aronow2019note]. Notwithstanding, the results presented in the following are robust for excluding non-attentive respondents.


## Free Choice Enables Opinion Change

As a first step, we examine average treatment effects of the forced exposure and free choice conditions relative to the control group that did not have access to the tweet or news article. For each of the five outcome measures, we estimate a linear regression with two treatment indicators as main independent variables (the control condition is the reference category) while controlling for a set of pre-treatment covariates and sociodemographic characteristics to increase statistical power [c.f., @bowers2011making; @clifford2020increasing]. Figure \ref{fig:m1} displays the estimated treatment effects based on these models.[^4] Since the measures of factual beliefs are dichotomous (correct vs. incorrect), the first set of coefficients examining belief change can be interpreted as linear probability models, whereas the remaining coefficients can be interpreted as average treatment effects where the (quasi-)continuous outcome variable has been rescaled to range from zero to one. We use a linear probability model instead of a logit or probit specification in order to facilitate the direct comparison between outcomes. The linear probability model is particularly appropriate when analyzing experimental data with dichotomous outcomes, since the parameter estimate can be directly interpreted as the average marginal treatment effect on the probability scale [see @angrist2008mostly;@greene2008econometric for details].

[^4]: Full regression tables including controls can be found in Appendix C.

\singlespace

```{r m1, fig.height=2, fig.width=7, fig.cap="\\label{fig:m1}Treatment effects of forced exposure and free choice manipulation (vs. control). Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 90\\% (thick line) and 95\\% (thin line) confidence intervals based on robust standard errors. Appendix C displays full model results."}
p1
```

\doublespace

\noindent Compared to the control condition, the proportion of correct responses regarding the employment and total value of sales by immigrant-owned businesses is about 20 to 30 percentage points higher among participants who read the tweet and news story. This is a substantively large effect and it is illustrative of the fact that participants systematically underestimated the economic contributions of immigrant-owned business if they were not given any additional information.

Turning to the effect of corrective information on interpretations, we find smaller, but still statistically significant treatment effects. After reading the tweet and news story, participants provided a more favorable assessment regarding the number of jobs created by immigrants as well as the relative size of their tax contributions. As before, this effect is significant for both the forced exposure and the free choice conditions.

Lastly, the treatment effect of forced exposure to corrective information largely diminishes when focusing on opinion change as the outcome of interest, which is consistent with previous experimental evidence [e.g., @hopkins2019muted]. In contrast, however, we do observe a small but statistically significant increase in general support for legal immigration among participants in the free choice condition compared to the control group. The finding that people's opinions toward legal immigration only change in response to *voluntary* exposure to corrective information is consistent with the argument that freedom of choice reduces negative affect and counter-arguing towards the source [@stroud2019consequences]. Before drawing any definite conclusions regarding this proposed mechanism, however, we need to explore the impact of media preferences and source consistency in this context. This will be the focus of the subsequent section.

Summarizing our results thus far, the finding that estimated treatment effects are smaller for interpretations and opinions than for beliefs strongly supports Hypothesis 1. In addition, differences between the forced exposure and free choice conditions appear fairly limited across outcomes. Updating beliefs and interpretations as a response to misinformation corrections is relatively common and independent of how people gain access to them. Only if people are allowed to choose their information source, however, do we observe that they change their opinions about the issue. While this is at least suggestive evidence that discretion over media diets is a potentially important factor facilitating opinion change, it should be noted that the difference between both treatment effects themselves is not statistically significant [see also @gelman2006difference]. Overall, these results lend at least some support to Hypothesis 2. Next, we are going to incorporate people's preferences over specific media sources in the analysis to further corroborate our findings.


## Opinion Change is Driven by Voluntary Exposure to Inconsistent Sources

At the beginning of our survey experiment, we included a battery of questions regarding people's usual media diet. Based on these items, we can distinguish whether participants in the treatment conditions were exposed to an information source that is consistent or inconsistent with their usual media preferences (if they usually prefer to watch more Fox News than MSNBC and vice versa), or if the information source is neutral (if they prefer neither Fox News nor MSNBC as part of their usual media diet). Figure \ref{fig:m2} repeats the previous analysis examining treatment effects on beliefs, interpretations, and opinions---but now differentiating participants in the forced exposure and free choice conditions by source consistency.

\singlespace

```{r m2, fig.height=3.5, fig.width=7.1, fig.cap="\\label{fig:m2}Treatment effects of forced exposure and free choice manipulation (vs. control) conditional on consistency between media preference and information source. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 95\\% (thin line) and 90\\% (thick line) confidence intervals based on robust standard errors. Appendix C displays full model results."}
p2
```

\doublespace

\noindent Focusing first on beliefs and interpretations as outcomes, we observe slightly larger treatment effects for participants who were exposed to an information source that is consistent with their usual media diet---a pattern that holds in the forced exposure as well as the free choice condition. In fact, in three out of four analyses, the information treatment had no statistically significant effect on people's interpretations regarding the economic benefits of legal immigration if it came from an inconsistent source, whereas exposure to a consistent source was always associated with more favorable interpretations. This result largely supports our third hypothesis that corrections will have stronger effects if the information source is consistent with respondents' media preferences.

Interestingly, this pattern is reversed for opinion change as a response to the news story. To the extent that the positive treatment effect of the free choice condition on opinions reported in Figure \ref{fig:m1} is solely driven by people's tendency to seek out consistent sources, we would expect a similar effect when focusing on forced exposure to consistent sources. This is not the case. Regardless of whether participants were given a news source that is consistent with their usual media diet, the information treatment in the forced exposure condition had no effect on subsequent opinions regarding the desired level of immigration in the U.S. In the free choice condition, on the other hand, we do find evidence for opinion change compared to control condition. Surprisingly, however, it is exposure to *inconsistent* sources in the free choice condition that ultimately results in significant opinion change.

\singlespace

```{r m4, fig.height=2, fig.width=6.5, fig.cap="\\label{fig:m4}Difference in treatment effects of free choice manipulation (vs. forced exposure) conditional on exposure to information source that is inconsistent with media preference. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger treatment effect for voluntary (vs. involuntary) exposure to inconsistent source. 95\\% (thin line) and 90\\% (thick line) confidence intervals based on robust standard errors. Appendix C displays full model results."}
p4
```

\doublespace

\noindent To further corroborate this finding, we now directly compare the effect of voluntary and involuntary exposure to inconsistent sources. Specifically, we reduce the sample to include only participants who were exposed to a news source that was inconsistent with their usual media diet. We then run regressions using the same specifications as before, now only including a single treatment indicator for the free choice condition. Note that since this specification omits the control group and instead uses forced exposure to inconsistent sources as the reference category, the coefficients can be directly interpreted as the differences in treatment effects between the free choice and forced exposure condition. The results are displayed in Figure \ref{fig:m4}.

Conditional on exposure to an inconsistent source, there are no clear differences in treatment effects on beliefs and related interpretations. However, participants who were exposed to inconsistent sources in the free choice condition reported more favorable opinions towards immigrants than participants who were exposed to inconsistent sources in the forced exposure condition. This finding is quite remarkable considering the fact that regardless of the news organization, the actual content of the tweet and article was constant across all treatments.

In sum, changing people's minds by giving them free choice over their media diet is not driven by the ability to choose consistent news sources. On the contrary, only participants who voluntarily accessed information from an inconsistent source reported significantly different opinions than the control group. In the next section, we explore potential explanations for this striking result.

<!--JJ comments: in this section, need to say more about why consistent sources are more persuasive for changing interpretations but inconsistent sources are more persuasive when it comes to changing opinions.-->


## The Role of Self-Selection, Pre-treatment Attitudes, and Ambivalence[^5]

[^5]: The analyses in this section were not preregistered and should therefore be considered exploratory.

When evaluating differences between voluntary and involuntary exposure to inconsistent sources, we have to keep in mind that conditioning on source selection in the free choice condition makes it challenging to provide a clear causal interpretation. To the extent that some people are systematically more likely to self-select inconsistent exposure, any resulting imbalance in pre-treatment confounders could jeopardize our inferences regarding the causal effect of corrective information.[^6] Given our between-subjects design, the crucial question then becomes whether people who are willing to access inconsistent sources (a) hold systematically different pre-treatment attitudes or (b) respond differently to the treatment itself?

[^6]: See Appendix A.II for an overview of respondents' media preferences and source consistency across treatment groups, and Appendix and A.III for the determinants of choosing Fox News in the free choice condition.

Thus, the most obvious alternative explanation for diverging opinions in response to voluntary and involuntary exposure to inconsistent sources is that both treatment groups may simply have different attitudes to begin with. However, all our analyses discussed hitherto include statistical controls for pre-treatment immigration attitudes, racial stereotypes, ideology, partisanship, and basic sociodemographics---rendering potential confounding due to these (observed) characteristics unlikely. A related concern may be that inconsistent sources are more likely to be selected by people who prefer MSNBC rather than Fox (or vice versa). First, such imbalances would be problematic since media preferences are correlated with political predispositions [e.g., @stroud2011niche]. Second, since we hold the article content constant across outlets, it may be viewed as less coherent with the usual narrative of Fox News and thereby influence people's receptivity. These concerns are alleviated by the fact that exposure to Fox News and MSNBC is split evenly among participants who selected inconsistent sources, which implies that the ratio of both outlets is balanced between the free-choice and forced exposure condition. Furthermore, additional analyses in Appendix B.I suggest that there are no differences in average choice-specific treatment effects (ACTEs)[^8] between people who prefer Fox or MSNBC and that---if anything---people who usually prefer MSNBC appear more biased against Fox News than people who usually prefer Fox News are biased against MSNBC.

[^8]: See @knox2019design for details on estimating ACTEs in PICA designs.

Although the results are therefore unlikely to be driven by pre-treatment differences in support for immigration or other predispositions, there might still be systematic discrepancies in the nature of people's attitudes. Specifically, people who select inconsistent sources may be more ambivalent about immigration and therefore more open to opinion change [e.g., @lavine2012ambivalent]. While our questionnaire did not include a pre-treatment measure of ambivalence, we can assess the plausibility of this alternative explanation by leveraging open-ended responses included at the end of our survey. After answering both questions measuring people's *interpretations* regarding the economic contributions of immigrants (by paying taxes and creating jobs), participants were asked to explain their previous assessment in a few sentences.[^7] To the extent that there are differences in pre-treatment ambivalence between voluntary and involuntary exposure to inconsistent information, these should also manifest in open-ended responses after reviewing the article. We measure ambivalence using the well-established LIWC dictionary [@pennebaker2015development], which includes markers for tentative language (e.g., maybe, perhaps, guess) that indicate uncertainty about a topic [@tausczik2010psychological]. The results are displayed in Figure \ref{fig:m5}.

[^7]: See Appendix D.III for full question wording.

\singlespace

```{r m5, fig.height=2, fig.width=4.5, fig.cap="\\label{fig:m5}Difference in tentative language in open-ended responses of respondents who were exposed to inconsistent information in the free choice and forced exposure condition. Tentative words based on LIWC dictionary, including 95\\% (thin line) and 90\\% (thick line) confidence intervals."}
p5
```

\doublespace

\noindent Focusing only on respondents who were exposed to an outlet that was inconsistent with their media preference, there are no significant differences in the percentage of tentative words in open-ended responses between the forced exposure and free choice conditions. If anything, participants appear less ambivalent after voluntary exposure to an inconsistent source than after involuntary exposure to an inconsistent source. In the context of our analyses, this null finding (i.e., the absence of differences in post-treatment ambivalence) strongly suggests the absence of pre-treatment differences in ambivalence, unless we are willing to assume that there are heterogeneous treatment effects that perfectly cancel out prior differences in ambivalence. We replicate the same result using an alternative measurement approach in Appendix B.II. Overall, it is therefore unlikely that the observed opinion change in response to voluntary exposure to inconsistent sources can be explained by attitude ambivalence prior to receiving the treatment.

In sum, while we cannot fully rule out the possibility that people who self-select inconsistent sources have substantively different (or more ambivalent) pre-treatment attitudes, it appears more plausible that the patterns reflect differences in people's receptiveness to corrective information. From a theoretical perspective, this could be explained by the fact that giving people freedom of choice decreases reactance and cognitive dissonance and thereby reduces counter-arguing [@stroud2019consequences]. Given that we do not observe opinion change in response to voluntary exposure to *consistent* information, however, this explanation alone appears to be incomplete as well. In addition to freedom of choice, what is needed for corrective information to be effective is that people are sufficiently motivated to seek out alternative viewpoints in the first place.


# Discussion and Conclusion

The apparent pervasiveness of misinformation across a wide range of political issues is exacerbated by an increasingly polarized media environment where people have unprecedented access to a wide variety of media sources. When it comes to the effectiveness of corrective interventions, revising people's factual *beliefs* is relatively easy, while changing their underlying *opinions* is hard. Yet, previous research in this context neglected the role of selective exposure and endogenous information search as moderating the potential attitudinal impact of corrective information. Our study fills this gap in the literature by employing an experimental design that allows a subset of participants to choose their information source. Holding the actual content constant, we find that the ability to choose news sources facilitates opinion change. However, the effect of people's discretion over their information intake is not driven by their tendency to access sources that are consistent with their usual media diet. Rather, it is the voluntary exposure to inconsistent sources that results in opinion change.

Of course, our findings are not without limitations. Most importantly, it is worth emphasizing again that conditioning on (in)consistent exposure in the free choice condition makes it difficult to provide a clear causal interpretation of the effects. While our analyses control for political predispositions and pre-treatment immigration attitudes, we cannot fully rule out the possibility that people who self-selected into exposure to an inconsistent source had substantively different or more ambivalent attitudes before receiving the treatment. However, given our exploratory examination of self-selection and ambivalence, it seems more likely that people who self-select inconsistent sources are ultimately more receptive to corrective information (rather than holding different baseline attitudes or being ambivalent). In addition, the fact that we do observe significant treatment effects for the free choice condition (and not for the forced exposure condition) across the entire sample further alleviates concerns about pre-treatment confounding, since this relationship cannot be explained by self-selection alone. Notwithstanding, additional research is needed to further corroborate this conclusion by examining opinion change in response to misinformation corrections in the context of a within-subjects design.

Overall, our findings indicate that discretion over information sources facilitates opinion change in response to corrective information---particularly when people are willing to consider alternative views. Future studies on misinformation should therefore incorporate endogenous information search as a crucial component of their experimental designs, and, from a theoretical perspective, re-orient their attention to people's underlying motivations to seek out different sources [e.g., @kunda1990case]. In terms of policy implications, our research strongly suggests that encouraging people to voluntarily access alternative media outlets may be a more effective strategy to combat misinformation than providing fact-checks alone.

<!-- elaborate on accuracy motivation and related predispositions to be open-minded -->


\clearpage
\parskip=10pt
\singlespace
