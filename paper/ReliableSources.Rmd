---
title: "Reliable Sources?"
subtitle: "Correcting Misinformation in Polarized Media Environments"
author:
  - Patrick W. Kraft
  - Nicholas R. Davis
  - Taraleigh Davis
  - Amanda Heideman
  - Jason T. Neumeyer
  - Shin Young Park
date: |
  |
  | University of Wisconsin-Milwaukee 
  |
  | \today
  |
  |
abstract: >-
  Various pressing issues at the center of today's politics--such as immigration, climate change, or the recent coronavirus pandemic--are imbued with misinformation. A growing body of research therefore explores the potential impact of providing corrective information. However, while such interventions appear to reduce people's factual misperceptions, they have little to no effect on their underlying attitudes. This study examines how the impact of corrective information on beliefs and attitudes is moderated by media choice. In our survey experiment, participants are asked to read a news article published by Fox News or MSNBC, each highlighting the positive economic impact of legal immigration in the United States. While the news content is held constant across sources, our treatment manipulates whether participants are allowed to freely choose a media outlet or are randomly assigned to one of them. Our results illustrate how people's media choice moderates the effectiveness of corrective information: While factual misperceptions are easily corrected regardless of how people gained access to the information, subsequent opinion change is conditional on people's prior willingness to seek out alternative sources. As such, encouraging people to broaden their media diet may be more effective to combat misinformation than disseminating fact-checks alone.
reference-section-title: References
bibliography: '../../bibliography/Lab.bib'
fontsize: 12pt
geometry: margin=1in
linestretch: 1.5
output: 
  pdf_document:
    number_sections: false
    template: null
    fig_caption: yes
header-includes:
  \renewcommand{\familydefault}{\sfdefault}
  \usepackage{float}
  \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r code}
## Load packages, data, analyses
source("../code/02-analysis.R")
```

\clearpage


Citizens in western democracies hold wide-ranging and systematic misperceptions about immigrants to their home countries. For example, people usually overestimate the total number of immigrants or the proportion of immigrants that are dependent on social welfare [e.g., @alesina2019immigration]. Given this extensive spread of misinformation, various studies examined how corrective information may affect people's underlying attitudes towards immigration, albeit with limited success. Although corrective information may alleviate factual misperceptions, it rarely affects people's underlying attitudes [see for example @hopkins2019muted; @thompson2019might].

A possible explanation for this apparent disconnect could be that factual information is simply irrelevant for attitude formation and---if anything---serves as a mere justification for people to rationalize their existing predispositions towards immigrant populations. However, the extent to which people engage such motivated reasoning is not without limits---as people have been shown to update their prior beliefs after reaching a "tipping point" of counter-attitudinal information [@redlawsk2010affective]. Furthermore, recent research on immigration attitudes demonstrate the persuasiveness of certain interventions such as canvassing [@kalla2020reducing].

Why do researchers frequently fail to find evidence of attitude change after providing respondents with corrective information? We argue that most experimental designs in this area are inconclusive because they omit a crucial mechanism: people's discretion over whether to engage with a given information source or not. Specifically, studies usually employ simple random assignment of informational treatments without considering people's selective exposure. Unfortunately, such a set-up does not allow us to estimate the quantity of interest that is ultimately of key interest: the effect of misinformation corrections among *people who would have chosen to access the information in the first place* [@benedictis2019persuading; @knox2019design].

We address these shortcomings of previous research by implementing an experimental design that varies both, the source of misinformation corrections as well as the process through which people access the information. Specifically, we conduct an online survey experiment on the effectiveness of corrective information about immigration. Depending on the experimental condition, participants are either able to freely choose--or are assigned to--an article published by different news channels (Fox News vs. MSNBC), which discusses the economic impact of legal immigration. Crucially, our design allows us to differentiate how the information treatment impacts factual beliefs, how they are interpreted, as well as broader attitudes towards immigration. The results indicate that while the correction of factual misperceptions is does not depend on media choice, subsequent attitude change is conditional on people's willingness to seek out alternative sources.

Taking into account endogenous information search in studies of misinformation corrections is crucial in our rapidly changing media environment where people have unprecedented control over their information diets [see also @iyengar2009red]. While people can access an ever-growing set of news outlets of varying quality, we only have a limited understanding how these systemic changes in information channels moderate the effectiveness of corrective information itself. Past research mostly focused on the effect of different _types_ of misinformation corrections. This study contributes to the literature by shifting the focus to the question of _how_ and _from where_ corrective information reaches people.


# Why misinformation corrections (often) fail

To the extent that people rely on inaccurate factual beliefs to form their opinions, misinformation can severely impede democratic representation by inducing collective preferences that systematically diverge from a more informed public [@kuklinski2000misinformation]. For instance, earlier studies focusing on aggregate opinion estimated that increasing individual information levels results in altered preferences of the electorate [e.g., @bartels1996uninformed; @althaus1998information]. Experimental studies examining change in individual attitudes, however, only found scant evidence for information treatments impacting peoples underlying opinions [see @flynn2017nature for an overview].

Focusing on misinformation in the context of immigration, @hopkins2019muted conducted multiple survey experiments informing participants about the size of the foreign-born population in the US---a statistic that is systematically overestimated by people in the absence of corrective information. In other words, many Americans are systematically misinformed, and this misinformation is associated with attitudes towards minority groups. Across seven separate survey experiments, the authors find that "accurate information does little to affect attitudes toward immigration, even though it does reduce the perceived size of the foreign-born population. [...] Misperceptions about the size of minority groups may be a consequence, rather than a cause, of attitudes toward those groups" [@hopkins2019muted, 315]. The authors therefore suggest that attitudes towards immigration resist change because they are grounded in more fundamental predispositions that are independent of the factual premise [see also @hainmueller2014public]. 

In sum, changing people's minds by providing corrective information is far from easy---especially when it comes to deeply held beliefs that are connected to people's identities [@nyhan2019taking]. However, this does not imply that new facts are bound to have no attitudinal consequences whatsoever. Although people engage in motivated reasoning and resist counter-attitudinal evidence [@Taber2006], there is some evidence that they are not completely immune to it [@redlawsk2010affective]. Before turning our discussion to a potential mechanism that may facilitate such attitude change, we need to begin by developing a clear conceptualization of different types of updating that may result from exposure to corrective information.


## Differentiating factual beliefs, interpretations, and opinions

Building on a framework developed in @gaines2007same, we define factual *beliefs* as assessments of the state of the world that are (at least in principle) intersubjectively observable and can therefore be either true or false. For example, the statement "Immigrant-owned businesses employed almost 8 million American workers in 2019" describes a factual belief that is objectively verifiable and--importantly--completely void of evaluative components. As we will further discuss below, it turns out that people are systematically misinformed about the number of workers employed by immigrant-owned businesses in the sense that they consistently underestimate this statistic. Corrective information in this example would simply consist of an accurate estimate, which, given previous evidence using similar designs [e.g., @hopkins2019muted], should be fairly effective in reducing (factual) misperceptions.

Incorrect factual beliefs only impede democratic representation to the extent that they affect peoples preferences [@kuklinski2000misinformation]. As such, it seems insufficient to consider the effect of misinformation corrections on factual beliefs alone. Rather, we need to examine how they influence subsequent evaluations. We define the step of adding immediate evaluative components to factual beliefs as *interpretations*. Continuing our previous example, a possible interpretation could be the following statement: "Immigrants improve the U.S. economy by creating additional jobs." This statement is still grounded in knowable facts such as the number of people employed by immigrant-owned businesses, but it contains evaluative components that are driven by implicit premises about potential economic "downsides" of immigration. Holding everything else constant, corrective information about the actual number of workers employed by immigrant-owned businesses should lead to a more positive assessment of the economic benefits of immigration. However, there is substantial leeway for people to interpret the same facts differently depending on their political predispositions [e.g., @gaines2007same].

Lastly, we define *opinions* as evaluative judgments that are formed about the state of the world, but that are not necessarily based on verifiable facts. An example for an opinion in our context would be the statement "The number of immigrants from foreign countries should be increased." Of course, this statement might be informed by objective facts about the economic impact of immigrant-owned business, but it certainly does not have to be. As such, corrective information can only be expected to have limited effects on opinions as these are largely driven by more fundamental predispositions.

How does this conceptualization of beliefs, interpretations, and opinions help us understand potential impact of corrective information? @gaines2007same uses this framework to differentiate four different types of updating as a response to a changing state of the world:

1. **Complete Updating:** \hspace{0.5em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
2. **Fact Avoidance:** \hspace{2.4em} reality **| |** beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
3. **Meaning Avoidance:** \hspace{0.4em} reality $\rightarrow$ beliefs **| |** interpretations $\rightarrow$ opinions
4. **Opinion Avoidance:** \hspace{0.85em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations **| |** opinions

Under complete updating, new factual information directly shapes beliefs about the state of the world, which in turn affects relevant interpretations, and ultimately results in opinion change. Consequently, incomplete updating despite new information could be due to a lack of belief updating (fact avoidance), interpretations that resist altered beliefs (meaning avoidance), or opinions driven by predispositions alone (opinion avoidance). Within this framework and considering the arguments outlined above, we can state the first hypothesis regarding the effectiveness of misinformation as follows:

> *Hypothesis 1:* Misinformation corrections have stronger effects on people's factual **beliefs** than their related **interpretations** or **opinions**.

In other words, while complete fact avoidance is relatively rare when people encounter corrective information, meaning avoidance and (especially) opinion avoidance is more common. Unfortunately, since few studies on misinformation corrections rely on an explicit distinction between these types of incomplete updating, surprisingly little is known about the determinants that make one type more likely than another. In the following section, we are going to argue that the source of corrective information is a crucial moderator in this context.


## The role of selective exposure and source credibility

Despite the fact that there is burgeoning interdisciplinary research on misinformation corrections, most experimental studies in this area rely on relatively simple designs that randomly assign different types of informational treatments to participants. While such designs have certain advantages such as straightforward causal identification, they essentially ignore a crucial aspect of our media environment: people's discretion over their individual media diet and the information they decide to access. There are notable examples of research in related areas that directly address selective exposure as part of their experimental designs---such as recent work on media hostility [@arceneaux2012polarized], persuasion [@benedictis2019persuading], and political knowledge [@leeper2020raising]. To our knowledge, however, no experimental study on misinformation corrections to date takes similar steps to account for endogenous media choice. This is surprising since individual media environments are becoming increasingly diverse and polarized [see @stroud2017selective for an overview], which makes it relatively easy for people to avoid counter-attitudinal corrective information [@guess2020exposure]. As such, prior studies do not allow us to estimate a key quantity of interest: the effect of misinformation corrections among people who would have chosen to access the information in the first place [@benedictis2019persuading].

Considering our differentiation between beliefs, interpretations, and opinions, we argue that selective exposure is a key mechanism that influences whether misinformation corrections ultimately result in complete updating, opinion avoidance, meaning avoidance, or even fact avoidance. People who are exposed to a random piece of information that they themselves did not seek out---as it usually happens in most misinformation experiments---might still be open to updating their factual beliefs, but they may be less likely to incorporate the new information in their interpretations and subsequent opinions than if they voluntarily chose to access the information. We therefore have the following expectation regarding the effect of the ability to choose information sources:

> *Hypothesis 2:* Misinformation corrections have stronger effects if people are able to **choose** their information source. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

In other words, we expect that meaning avoidance and opinion avoidance are less common if people have discretion over what information to access. This relationship may be driven by two potential mechanism. On the one hand, the initial decision to access a certain source may compel people to be more open to accepting the information provided therein. News reports usually contextualize information and therefore readily provide potential interpretations of the underlying facts. Whether people adopt these interpretations along with the factual information may be partly driven by people's initial motivation to access the information---presumably more so than when considering factual information alone.

A second and closely related mechanism is source credibility driven by people's media preferences. While previous research on misinformation corrections has largely ignored the question of selective exposure, multiple studies examined the role of source credibility. For example, @guillory2013correcting found that corrective information is especially effective if it comes from a source perceived to be trustworthy. Similarly, @berinsky2017rumors presented evidence that the rebuttal of rumors in the context of health care reform were more effective when politicians issuing the correction act counter to their personal and political interests. Other studies, however, indicate that the source is less consequential for the effectiveness of corrections [e.g., @swire2017processing]. Notwithstanding, we expect that people's media preferences should influence the receptivity to corrective information:

> *Hypothesis 3:* Misinformation corrections have stronger effects if the information source is **consistent** with people's media preferences. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

This hypothesis represents the classic source credibility argument since people should perceive their preferred information sources as more trustworthy. As such, it can be expected that meaning avoidance and opinion avoidance is less common if people are exposed information provided by a news organization they view favorably.

A skeptical reader might argue that *Hypothesis 2* and *Hypothesis 3* are essentially two sides of exactly the same coin. We contend that it is ultimately an empirical question whether the effect of the ability to choose media sources is solely driven by media preferences and related source credibility. Our empirical analyses---to which we are going to turn next---provide at least some evidence that this may not be the case.


# Research Design

The goal of our study is to explore how the way people access corrective information influences its potential to change related beliefs, interpretations, and opinions. Our experimental framework builds on the Preference-Incorporating Choice and Assignment (PICA) design [@benedictis2019persuading; @knox2019design], where one group of participants is randomly assigned to information treatments from different sources while another group is allowed to freely choose which source to access. This study was conducted using a sample of 600 participants recruited via Amazonâ€™s Mechanical Turk.

<!-- Add discussion of specific advantages of this design -->

Figure \ref{fig:flow} displays an overview of the experimental design. Participants are first asked to answer a set of pre-treatment questions regarding their media preferences and their attitudes towards immigration. Subsequently, they are randomly assigned to a free choice treatment condition, a forced exposure treatment condition, or a control group. 

```{r, flow, fig.cap="\\label{fig:flow}Survey flow and overview of the experimental design. See Appendix for further details such as question wording and information treatments."}
knitr::include_graphics("../prereg/Lab-Graphic.jpg")
```

Participants in the free choice condition are asked to choose whether they want to see a recent breaking news tweet from either FoxNews or MSNBC:

> In the following section, we are going to show you a random tweet drawn from the accounts of [two/several] large news organizations. **You can choose from which Twitter account the random tweet will be drawn.** Afterwards, we are going to ask you some questions about the content of the news story.

Participants in the forced exposure condition read almost the same message, the only difference being that it omitted the bold sentence telling them that they can choose from which twitter account the random tweet will be drawn. Depending on their preference (in the free choice condition) or random assignment (in the forced exposure condition), participants are then shown one of the following tweets displayed in Figure \ref{fig:tweets}, which links to a news story focusing on immigrant-owned businesses in the U.S. It is important to note that both tweets contain exactly the same information, so regardless of which news organization participants chose (or were assigned to), the information itself is held constant.

```{r, tweets, fig.show="hold", out.width="50%", fig.cap="\\label{fig:tweets}Information treatment on the size of immigrant-owned businesses in the U.S. from two different sources (FoxNews or MSNBC)."}
knitr::include_graphics(c("../material/tweets/fox_popular.png", "../material/tweets/msnbc_popular.png"))
```

After viewing one of the tweets, participants are asked to read the corresponding article. As before, the content of the news article is held constant across sources in either condition.[^1] Compared to previous implementations of the PICA framework where the content was not held constant across sources [@benedictis2019persuading; @knox2019design], our design allows us to directly compare the effects of free choice and forced exposure by ensuring that differences between treatment groups are not the result of the structure, content, or tone of different stories. Finally, participants who are randomly assigned to the control group skip the tweet and article entirely and move directly from the pre-treatment battery to the post-treatment outcome measures.

[^1]: See Appendix for full article.

In our analysis, we consider five different outcome measures that correspond to beliefs, interpretations, and opinions related to the economic impact of legal immigration in the U.S. The full question overview is displayed in Table \ref{tab:outcomes}. Two items targeting factual *beliefs* directly ask for statistics regarding the number of workers employed by immigrant-owned businesses as well as the total amount of sales revenue of immigrant-owned businesses. Both questions offer five response options (one of which is accurate) and the correct information is mentioned in the tweet as well as the news article.

In order to measure *interpretations* consistent with the theoretical conceptualization discussed above, we asked respondents two additional questions about whether they believe that immigrants add to the economy by creating additional jobs and whether they contribute more by paying taxes than they take out by using health and social services. Responses for both items are measured on an 11-point scale.

Lastly, we measure *opinions* by asking for the participants' general preference regarding the number of immigrants from foreign countries who are permitted to come to the U.S. Responses for this item are measured on a 5-point scale ranging from "increased a lot" to "decreased a lot."

```{r outcomes}
tribble(
  ~Belief, ~Interpretation, ~Opinion,
  "Across the United States, how many workers--immigrant and US-born--do you think are employed by immigrant-owned businesses?",
  "On average, would you say that people who come to live here from other countries will take jobs away from people already here or add to the economy by creating additional jobs?",
  "Do you think the number of immigrants from foreign countries who are permitted to come to the United States to live should be [increased/left the same/decreased]", "", "", "",
  "Taking your best guess, what was the total amount of sales revenue of immigrant-owned businesses in the last year?",
  "Most people who come to live in the U.S. work and pay taxes. They also use health and social services. On balance, do you think people who come here take out more than they put in or put in more than they take out?",
  ""
) %>%
  knitr::kable("latex", 
               caption = "\\label{tab:outcomes}Overview of outcome variables measuring beliefs, interpretation, and opinions related to the economic impact of legal immigration in the U.S.",
               booktabs = TRUE) %>%
  kableExtra::column_spec(1, width = "4cm") %>%
  kableExtra::column_spec(2, width = "6cm") %>%
  kableExtra::column_spec(3, width = "5cm")
```

# Results 

Compared to previous studies, the outcome measures described above allow for a much more fine-grained differentiation of different types of (incomplete) updating as a response to misinformation corrections. Now, we are going to examine the role of media preferences and the ability to choose information sources in this context.

<!-- ## Corrective information and media choice -->

\clearpage

## Free Choice Enables Opinion Change

<!-- People Change their Minds if They are Allowed to Choose their Information Source  -->

```{r m1, fig.height=2, fig.width=7, fig.cap="\\label{fig:m1}Treatment effects of forced exposure and free choice manipulation (vs. control). Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 95\\% confidence intervals based on robust standard errors. Full model results included in the appendix."}
p1
```

## Opinion Change is Driven by Voluntary Exposure to Inconsistent Sources

```{r m2, fig.height=3.5, fig.width=7.1, fig.cap="\\label{fig:m2}Treatment effects of forced exposure and free choice manipulation (vs. control) conditional on consistency between media preference and information source. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 95\\% confidence intervals based on robust standard errors. Full model results included in the appendix."}
p2
```

<!-- ## Voluntary and Involuntary Exposure to Inconsistent Sources -->

```{r m4, fig.height=2, fig.width=6.5, fig.cap="\\label{fig:m4} Difference in treatment effects of forced exposure and free choice manipulation conditional on exposure to information source that is inconsistent with media preference. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger treatment effect for voluntary (vs. involuntary) exposure to inconsistent source. 95\\% confidence intervals based on robust standard errors. Full model results included in the appendix."}
p4
```


# Discussion and Conclusion

<!-- discuss future directions -->

# References
