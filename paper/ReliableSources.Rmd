---
title: "Reliable Sources?"
#^[Presented at the 2020 Annual Meeting of the International Society for Political Psychology. We thank Jennifer Jerit and Pirmin Stöckle for helpful comments on previous versions of this manuscript.]"
subtitle: >
  Correcting Misinformation in Polarized Media Environments \vspace{10em}
#author:
#  - "Patrick W. Kraft^[Corresponding author, kraftp@uwm.edu]"
#  - Nicholas R. Davis
#  - Taraleigh Davis
#  - Amanda Heideman
#  - Jason T. Neumeyer
#  - Shin Young Park
#date: |
#  |
#  | University of Wisconsin-Milwaukee 
#  |
#  | \today
#  |
#  |
abstract: >-
  \noindent Various pressing issues at the center of today's politics---such as immigration, climate change, or the recent coronavirus pandemic---are imbued with misinformation. While a growing body of research demonstrates how corrective information can mitigate factual misperceptions among the public, these interventions tend to have little to no effect on people's underlying attitudes. This study examines how the impact of corrective information on beliefs and attitudes is moderated by media choice. In our survey experiment, participants are asked to read a news article published by Fox News or MSNBC, each highlighting the positive economic impact of legal immigration in the United States. While the news content is held constant across sources, our treatment manipulates whether participants are allowed to freely choose a media outlet or are randomly assigned to one of them. Our results illustrate how people's media choice moderates the effectiveness of corrective information. While factual misperceptions are easily corrected regardless of how people gained access to the information, subsequent opinion change is conditional on people's prior willingness to seek out alternative sources. As such, encouraging people to broaden their media diet may be more effective to combat misinformation than disseminating fact-checks alone.
reference-section-title: References
bibliography: '../../bibliography/Lab.bib'
fontsize: 12pt
geometry: margin=1in
linestretch: 1.5
output: 
  pdf_document:
    number_sections: false
    template: null
    fig_caption: yes
header-includes:
  \renewcommand{\familydefault}{\sfdefault}
  \usepackage{float}
  \usepackage{censor}
  \floatplacement{figure}{H}
  \parskip=0pt
  \parindent=20pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r code}
## Load packages, data, analyses
source("../code/02-analysis.R")
source("../code/03-liwc.R")
```

\thispagestyle{empty}
\clearpage
\setcounter{page}{1}

\noindent Citizens in western democracies hold wide-ranging and systematic misperceptions about immigrants to their home countries. For example, people usually overestimate the total number of immigrants or the proportion of immigrants that are dependent on social welfare [@alesina2019immigration]. These factual misperceptions are reinforced by the news media and, in turn, can foster biased attitudes and stereotypes [@Wright2020]. Given the extensive spread of misinformation, researchers from various disciplines started examining how corrective information may affect people's underlying attitudes [see @flynn2017nature for a review]. However, while corrective information may alleviate some factual misperceptions, it rarely affects people's underlying attitudes [@hopkins2019muted; @swire2020they].

A possible explanation for this apparent disconnect could be that factual information is simply irrelevant for attitude formation and---if anything---serves as a mere justification for people to rationalize their existing predispositions towards immigrant populations. Yet, the extent to which people engage such motivated reasoning is not without limits; they update their prior beliefs after reaching a "tipping point" of counter-attitudinal information [@redlawsk2010affective]. Furthermore, recent studies on immigration attitudes demonstrate the persuasiveness of certain interventions such as canvassing [@kalla2020reducing].

Why do researchers frequently fail to find evidence of attitude change after providing respondents with corrective information? We argue that most experimental designs in this area are inconclusive because they omit a crucial mechanism: people's discretion over whether to engage with a given information source or not. Specifically, studies usually employ simple random assignment of informational treatments without considering people's selective exposure. Unfortunately, such a set-up does not allow us to estimate the effect of misinformation corrections among people who would have chosen to access their preferred source to update information in the first place [see @benedictis2019persuading; @knox2019design for similar arguments].

We address these shortcomings by implementing an experimental design that varies both the source of misinformation corrections, as well as the process through which people access the information. Specifically, we conduct an online survey experiment on the effectiveness of corrective information about immigration. Depending on the experimental condition, participants are either able to freely choose--or are assigned to--an article published by different news channels (Fox News vs. MSNBC), which discusses the economic impact of legal immigration. Crucially, our design allows us to differentiate how the information treatment impacts factual beliefs, how they are interpreted, as well as broader attitudes towards immigration. The results indicate that while the correction of factual misperceptions does not depend on media choice, subsequent attitude change is conditional on people's willingness to seek out alternative sources.

Taking into account endogenous information search in studies of misinformation corrections is crucial in our rapidly changing media environment where people have unprecedented control over their information diets [@iyengar2009red]. While people can access an ever-growing set of news outlets of varying quality, we only have a limited understanding how these systemic changes in information channels moderate the effectiveness of corrective information itself. Past research mostly focused on the effect of different _types_ of misinformation corrections. This study contributes to the literature by shifting the focus to the question of _how_ and _from where_ corrective information reaches people.


# Why misinformation corrections (often) fail

To the extent that people rely on inaccurate factual beliefs to form their opinions, misinformation can severely impede democratic representation by inducing collective preferences that systematically diverge from a more informed public [@kuklinski2000misinformation]. For instance, earlier studies focusing on aggregate opinion estimated that increasing individual information levels results in altered preferences of the electorate [e.g., @bartels1996uninformed; @althaus1998information]. Experimental studies examining individual attitude change, however, only found scant evidence for information treatments impacting people's underlying opinions [see @flynn2017nature for an overview].

Focusing on misinformation in the context of immigration, @hopkins2019muted conducted multiple survey experiments informing participants about the size of the foreign-born population in the US---a statistic that is systematically overestimated by people in the absence of corrective information. In other words, many Americans are systematically misinformed, and this misinformation is associated with attitudes towards minority groups. Furthermore, "accurate information does little to affect attitudes toward immigration, even though it does reduce the perceived size of the foreign-born population. [...] Misperceptions about the size of minority groups may be a consequence, rather than a cause, of attitudes toward those groups" [@hopkins2019muted, 315]. The authors, therefore, suggest that attitudes towards immigration resist change because they are grounded in more fundamental predispositions that are independent of the factual premise [see also @hainmueller2014public]. 

In sum, changing people's minds by providing corrective information is far from easy---especially when it comes to deeply held beliefs that are connected to people's identities [@nyhan2019taking]. However, this does not imply that new facts are bound to have no attitudinal consequences whatsoever. Although people engage in motivated reasoning and resist counter-attitudinal evidence [@Taber2006], there is some evidence that they are not completely immune to it [@redlawsk2010affective]. Before turning our discussion to potential mechanisms that may facilitate such attitude change, we need to develop a clear conceptualization of different types of updating that may result from exposure to corrective information.


## Differentiating factual beliefs, interpretations, and opinions

Building on a framework developed in @gaines2007same, we define factual *beliefs* as assessments of the state of the world that are, at least in principle, intersubjectively observable and can therefore be either true or false. For example, the statement "Immigrant-owned businesses employed almost 8 million American workers in 2019" describes a factual belief that is objectively verifiable and, importantly, devoid of evaluative components. As we discuss below, people are systematically misinformed about the number of workers employed by immigrant-owned businesses in the sense that they consistently underestimate this statistic. Corrective information in this example would simply consist of an accurate estimate, which, given previous evidence using similar designs [e.g., @hopkins2019muted], should be effective in correcting factual misperceptions.

Incorrect factual beliefs only impede democratic representation to the extent that they affect people's preferences [@kuklinski2000misinformation]. As such, it would be insufficient to consider the effect of misinformation corrections on factual beliefs alone. Rather, we need to examine how they influence subsequent evaluations. We define the step of adding immediate evaluative components to factual beliefs as *interpretations*. Continuing our previous example, a possible interpretation could be the following statement: "Immigrants improve the U.S. economy by creating additional jobs." This statement is still grounded in knowable facts such as the number of people employed by immigrant-owned businesses, but it contains evaluative components that are driven by implicit premises about potential economic "downsides" of immigration. Holding everything else constant, corrective information about the actual number of workers employed by immigrant-owned businesses should lead to a more positive assessment of the economic benefits of immigration. However, there is substantial leeway for people to interpret the same facts differently depending on their political predispositions [e.g., @gaines2007same].

Lastly, we define *opinions* as evaluative judgments that are formed about the state of the world, but that are not necessarily based on verifiable facts. An example of an opinion in our context would be the statement "The number of immigrants from foreign countries should be increased." Of course, this statement might be informed by objective facts about the economic impact of immigrant-owned business, but it does not necessarily have to be. As such, corrective information can only be expected to have limited effects on opinions as these are largely driven by more fundamental predispositions.

How does this conceptualization of beliefs, interpretations, and opinions help us understand potential impact of corrective information? @gaines2007same uses this framework to differentiate four different types of updating as a response to a changing state of the world:

\vspace{.5em}

1. **Complete Updating:** \hspace{0.5em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
2. **Fact Avoidance:** \hspace{2.4em} reality **| |** beliefs $\rightarrow$ interpretations $\rightarrow$ opinions
3. **Meaning Avoidance:** \hspace{0.4em} reality $\rightarrow$ beliefs **| |** interpretations $\rightarrow$ opinions
4. **Opinion Disconnect:** \hspace{0.4em} reality $\rightarrow$ beliefs $\rightarrow$ interpretations **| |** opinions

\vspace{.5em}

\noindent Under complete updating, new factual information directly shapes beliefs about the state of the world, which in turn affects relevant interpretations, and ultimately results in opinion change. Consequently, incomplete updating despite new information could be due to a lack of belief updating (fact avoidance), interpretations that resist altered beliefs (meaning avoidance), or opinions driven by predispositions alone (opinion disconnect). Within this framework and considering the arguments outlined above, we therefore state our first hypothesis as follows:

\vspace{.5em}

> *Hypothesis 1:* Misinformation corrections have stronger effects on people's factual **beliefs** than their related **interpretations** or **opinions**.

\vspace{.5em}

\noindent Consistent with past research, we expect fact avoidance to be relatively rare when people encounter corrective information. Meaning avoidance and (especially) opinion disconnect, however, may be considerably more common. Unfortunately, since few studies on misinformation corrections rely on an explicit distinction between these types of incomplete updating, surprisingly little is known about the determinants that make one type more likely than another. In the following section, we are going to argue that the source of corrective information is a crucial moderator in this context.


## The role of media choice and source credibility

Notwithstanding the burgeoning interdisciplinary research on misinformation corrections, most experimental studies in this area rely on relatively simple designs that randomly assign different types of informational treatments to participants. While such designs have certain advantages such as straightforward causal identification, they ignore a crucial aspect of our media environment: people's discretion over their individual media diet and the information they decide to access. There are notable examples of research in related areas that directly address selective exposure as part of their experimental designs---such as recent work on media hostility [@arceneaux2012polarized], persuasion [@benedictis2019persuading], and political knowledge [@leeper2020raising]. To our knowledge, however, no experimental study on misinformation corrections to date takes similar steps to account for endogenous media choice. This is surprising since individual media environments are becoming increasingly diverse and polarized [@stroud2010polarization; @stroud2011niche], which makes it relatively easy for people to avoid counter-attitudinal corrective information [@guess2020exposure]. As such, prior studies do not allow us to estimate a key quantity of interest: the effect of misinformation corrections among people who would have chosen to access corrections in the first place [@benedictis2019persuading].

Building on our differentiation between beliefs, interpretations, and opinions, we argue that media choice is a key mechanism that influences whether misinformation corrections ultimately result in complete updating, opinion disconnect, meaning avoidance, or even fact avoidance. Prior studies suggest that people are willing to update their factual *beliefs* in response to corrective information regardless of whether they were able to choose a source. However, the reason that they seem less inclined to incorporate corrections in their *interpretations* and subsequent *opinions* may be because they are exposed to information that they did not seek out themselves---as it usually happens in most misinformation experiments. This argument is grounded in work by @stroud2019consequences, who develop a theoretical framework that explains how varying circumstances of information exposure---i.e., whether it was accessed voluntarily or not---impact individual responses to said information. Specifically, being forced to view content without freedom of choice generates reactance (i.e., negative affect and counter-arguing) and cognitive dissonance, even among those who are assigned to preferred content [@stroud2019consequences]. Thus, we can formulate the following expectation regarding the impact of being able to choose information sources:

\vspace{.5em}

> *Hypothesis 2:* Misinformation corrections have stronger effects if people are able to **choose** their information source. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

\vspace{.5em}

\noindent In sum, we expect that meaning avoidance and opinion disconnect are less common if people have discretion over what information to access. For instance, a large component of news articles consists of contextualizing information and thereby providing suitable interpretations of the underlying facts. The initial ability to select a news source may make people more willing to adopt the interpretations provided therein along with the factual information itself.

In addition to the hypothesized effect of people's ability to choose in and of itself, we consider a closely related mechanism centered on the impact of a given source itself. Although previous research on misinformation corrections has largely ignored the potential impact of people's freedom to select content, what has been studied extensively is the effect of the perceived credibility of a given source. For example, @guillory2013correcting find that corrective information is especially effective if it comes from a source perceived to be trustworthy. Similarly, @berinsky2017rumors presents evidence that the rebuttal of rumors in the context of health care reform was more effective when politicians issuing the correction act counter to their personal and political interests. Other studies, however, indicate that the source is less consequential for the effectiveness of corrections [e.g., @swire2017processing]. Notwithstanding, we expect that people's media preferences should influence the receptivity to corrective information:

\vspace{.5em}

> *Hypothesis 3:* Misinformation corrections have stronger effects if the information source is **consistent** with people's media preferences. These differences are more pronounced for **opinions** and **interpretations** than for beliefs.

\vspace{.5em}

\noindent This hypothesis follows directly from the aforementioned arguments surrounding source credibility since people should perceive their preferred media outlets as more trustworthy. As such, it can be expected that meaning avoidance and opinion disconnect is less common if people are exposed to information provided by a news organization they view favorably.

It is worth emphasizing that while Hypothesis 2 and 3 are clearly related, they focus on two conceptually distinct mechanisms. The former examines how constraints on people's freedom to choose sources reduce their willingness to incorporate misinformation corrections---regardless of individual predisposition towards a particular source itself. The latter hypothesis, on the other hand, explores the impact of people's perceived credibility of a given source---irrespective of whether it was accessed voluntarily or not. It is ultimately an empirical question to what extent either of these mechanisms enable opinion change in response to corrective information. Distinguishing both, however, has crucial implications for the development of effective interventions to mitigate misinformation. Fortunately, our experimental design---which we are going to turn to next---allows us to disentangle the relative impact of discretion over media sources and individual predispositions towards particular outlets.


# Research Design

The goal of our study is to explore how the way people access corrective information influences its potential to change related beliefs, interpretations, and opinions. Our experimental framework builds on the Preference-Incorporating Choice and Assignment (PICA) design [@benedictis2019persuading; @knox2019design], where one group of participants is randomly assigned to information treatments from different sources while another group is allowed to freely choose which source to access. Figure \ref{fig:flow} displays an overview of our study. The survey begins with a set of pre-treatment questions regarding their media preferences and immigration attitudes. Next, we randomly assign participants to a free choice, forced exposure, or control condition. Participants who receive the free choice treatment are informed that they will be shown a breaking news tweet and they are asked to decide from which media outlet the tweet should be taken (either Fox News or MSNBC). Participants in the forced exposure condition are not offered such a choice but are simply informed that they will be shown a breaking news tweet from a random media outlet.

```{r flow, fig.cap="\\label{fig:flow}Survey flow and overview of the experimental design. See Appendix D for the complete questionnaire."}
knitr::include_graphics("../prereg/Lab-Graphic.jpg")
```

\noindent Depending on their preference (in the free choice condition) or random assignment (in the forced exposure condition), participants are then shown one of the tweets displayed in Figure \ref{fig:tweets}, which links to a news story focusing on immigrant-owned businesses in the U.S. Importantly, both tweets contain exactly the same information, so regardless of which news organization participants chose (or were assigned to), the information itself is held constant. After viewing one of the tweets, participants are asked to read the corresponding article. As before, the content of the news article is held constant across sources in either condition.[^2]

[^2]: See Appendix D for the full news article.

\vspace{1em}

```{r tweets, fig.show="hold", out.width="50%", fig.cap="\\label{fig:tweets}Information treatment on the size of immigrant-owned businesses in the U.S. from two different sources (Fox News or MSNBC). Participants only view one of the tweets."}
knitr::include_graphics(c("../material/tweets/fox_popular.png", "../material/tweets/msnbc_popular.png"))
```

\noindent Compared to previous implementations of the PICA framework where the content was not held constant across sources [@benedictis2019persuading; @knox2019design], our design allows us to directly compare the effects of free choice and forced exposure while ensuring that differences between treatment groups are not the result of the structure, content, or tone of different stories. Finally, participants who are randomly assigned to the control group skip the tweet and article entirely and move directly from the pre-treatment battery to the outcome measures.

```{r outcomes}
tribble(
  ~Belief, ~Interpretation, ~Opinion,
  "Across the United States, how many workers--immigrant and US-born--do you think are employed by immigrant-owned businesses?",
  "On average, would you say that people who come to live here from other countries will take jobs away from people already here or add to the economy by creating additional jobs?",
  "Do you think the number of immigrants from foreign countries who are permitted to come to the United States to live should be [increased/left the same/decreased]", "", "", "",
  "Taking your best guess, what was the total amount of sales revenue of immigrant-owned businesses in the last year?",
  "Most people who come to live in the U.S. work and pay taxes. They also use health and social services. On balance, do you think people who come here take out more than they put in or put in more than they take out?",
  ""
) %>%
  knitr::kable("latex", 
               caption = "\\label{tab:outcomes}Overview of outcome variables measuring beliefs, interpretation, and opinions related to the economic impact of legal immigration in the U.S.",
               booktabs = TRUE) %>%
  kableExtra::column_spec(1, width = "4cm") %>%
  kableExtra::column_spec(2, width = "6cm") %>%
  kableExtra::column_spec(3, width = "5cm") %>% 
  kableExtra::kable_styling(latex_options =c("hold_position"))
```

\noindent For our analysis, we consider five different outcomes that correspond to beliefs, interpretations, and opinions related to the economic impact of legal immigration. The full question overview is displayed in Table \ref{tab:outcomes}. Two items targeting factual *beliefs* directly ask for statistics regarding the number of workers employed by immigrant-owned businesses as well as the total amount of sales revenue of immigrant-owned businesses. Both questions offer five response options,  (one of which is accurate) and the correct information is mentioned in the tweet as well as the news article. In order to measure *interpretations* consistent with the theoretical conceptualization discussed above, we asked respondents two additional questions about whether they believe that immigrants add to the economy by creating additional jobs and whether they contribute more by paying taxes than they take out by using health and social services. Lastly, we measure *opinions* by asking for the participants' overall preference regarding the number of immigrants who should be allowed to move to and live in the United States. Together, these outcome measures allow for a more fine-grained differentiation of possible types of (incomplete) updating than previous studies on the effectiveness of misinformation corrections. In the following section, we are going to leverage this differentiation to examine how the ability to choose information sources moderates their impact on beliefs, interpretations, and opinions.


# Results 

We preregistered our study on \censor{EGAP (Registration ID: 20191119AC)} prior to data collection.[^3] The survey was fielded on Amazon's Mechanical Turk (MTurk) in December 2019 with a sample of 600 respondents. We provide a summary of our sample demographics across treatment conditions in Appendix A. In general, respondents on MTurk tend to be younger, more liberal, and more educated than the average U.S. population [@huff2015these]. However, while MTurk samples are not representative of the broader U.S. population, they are more diverse than other convenience samples such as college students [@berinsky2012evaluating] and have been shown to be suitable for survey experiments [@krupnikov2014cross]. Following current best practices, our survey includes a script to screen out bots and respondents who mask their true location [@kennedy2020shape]. We also included attention checks at the end of our survey to make sure that respondents read the material carefully. Despite the fact that only a small proportion failed our attention checks (less than 10%), we decided not to drop any respondents in order to avoid post-treatment bias [@aronow2019note].

[^3]: A shortened and de-identified version of the registration and pre-analysis plan is included in Appendix E. 


## Free Choice Enables Opinion Change

As a first step, we examine average treatment effects of the forced exposure and free choice conditions relative to the control group that did not have access to the tweet or news article. For each of the five outcome measures, we estimate a linear regression with two treatment indicators as main independent variables (the control condition is the reference category) while controlling for a set of pre-treatment covariates and sociodemographic characteristics to increase statistical power [c.f., @bowers2011making; @clifford2020increasing]. Figure \ref{fig:m1} displays the estimated treatment effects based on these models.[^4] Since the measures of factual beliefs are dichotomous, the first set of coefficients examining belief change can be interpreted as linear probability models, whereas the remaining coefficients can be interpreted as average treatment effects where the (quasi-)continuous outcome variable has been rescaled to range from zero to one.

[^4]: Full regression tables including controls can be found in Appendix C.

\vspace{1em}

```{r m1, fig.height=2, fig.width=7, fig.cap="\\label{fig:m1}Treatment effects of forced exposure and free choice manipulation (vs. control). Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 90\\% (thick line) and 95\\% (thin line) confidence intervals based on robust standard errors. Appendix C displays full model results."}
p1
```

\noindent Compared to the control condition, the proportion of correct responses regarding the employment and total value of sales by immigrant-owned businesses is about 20 to 30 percentage points higher among participants who read the tweet and news story. This is a substantively large effect and it is illustrative of the fact that participants systematically underestimated the economic contributions of immigrant-owned business if they were not given any additional information.

Turning to the effect of corrective information on interpretations, we find smaller, but still statistically significant treatment effects. After reading the tweet and news story, participants provided a more favorable assessment regarding the number of jobs created by immigrants as well as the relative size of their tax contributions. As before, this effect is significant for both the forced exposure and the free choice conditions.

Lastly, the treatment effect of forced exposure to corrective information largely diminishes when focusing on opinion change as the outcome of interest, which is consistent with previous experimental evidence [e.g., @hopkins2019muted]. In contrast, however, we do observe a small but statistically significant increase in general support for legal immigration among participants in the free choice condition compared to the control group. The finding that people's opinions toward legal immigration only change in response to *voluntary* exposure to corrective information is consistent with the argument that freedom of choice reduces negative affect and counter-arguing towards the source [@stroud2019consequences]. Before drawing any definite conclusions regarding this proposed mechanism, however, we need to explore the impact of media preferences and source consistency in this context. This will be the focus of the subsequent section.

Summarizing our results thus far, the finding that estimated treatment effects are smaller for interpretations and opinions than for beliefs strongly supports Hypothesis 1. In addition, differences between the forced exposure and free choice conditions appear fairly limited across outcomes. Updating beliefs and interpretations as a response to misinformation corrections is relatively common and independent of how people gain access to them. Only if people are allowed to choose their information source, however, do we observe that they change their opinions about the issue. While this is at least suggestive evidence that discretion over media diets is a potentially important factor facilitating opinion change, it should be noted that the difference between both treatment effects themselves is not statistically significant [@gelman2006difference]. Overall, these results lend at least some support to Hypothesis 2. Next, we are going to incorporate people's preferences over specific media sources in the analysis to further corroborate our findings.


## Opinion Change is Driven by Voluntary Exposure to Inconsistent Sources

At the beginning of our survey experiment, we included a battery of questions regarding people's usual media diet. Based on these items, we can distinguish whether participants in the treatment conditions were exposed to an information source that is consistent or inconsistent with their usual media preferences (if they usually prefer to watch more Fox News than MSNBC and vice versa), or if the information source is neutral (if they prefer neither Fox News nor MSNBC as part of their usual media diet). Figure \ref{fig:m2} repeats the previous analysis examining treatment effects on beliefs, interpretations, and opinions---but now differentiating participants in the forced exposure and free choice conditions by source consistency.

\vspace{1em}

```{r m2, fig.height=3.5, fig.width=7.1, fig.cap="\\label{fig:m2}Treatment effects of forced exposure and free choice manipulation (vs. control) conditional on consistency between media preference and information source. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger probability of correct responses (Belief) or more liberal immigration attitudes (Interpretation \\& Opinion). 95\\% (thin line) and 90\\% (thick line) confidence intervals based on robust standard errors. Appendix C displays full model results."}
p2
```

\noindent Focusing first on beliefs and interpretations as outcomes, we observe slightly larger treatment effects for participants who were exposed to an information source that is consistent with their usual media diet---a pattern that holds in the forced exposure as well as the free choice condition. In fact, in three out of four analyses, the information treatment had no statistically significant effect on people's interpretations regarding the economic benefits of legal immigration if it came from an inconsistent source, whereas exposure to a consistent source was always associated with more favorable interpretations. This result largely supports our third hypothesis that corrections will have stronger effects if the information source is consistent with respondents' media preferences.

Interestingly, this pattern is reversed for opinion change as a response to the news story. To the extent that the positive treatment effect of the free choice condition on opinions reported in Figure \ref{fig:m1} is solely driven by people's tendency to seek out consistent sources, we would expect a similar effect when focusing on forced exposure to consistent sources. This is not the case. Regardless of whether participants were given a news source that is consistent with their usual media diet, the information treatment in the forced exposure condition had no effect on subsequent opinions regarding the desired level of immigration in the U.S. In the free choice condition, on the other hand, we do find evidence for opinion change compared to control condition. Surprisingly, however, it is exposure to *inconsistent* sources in the free choice condition that ultimately results in significant opinion change.

\vspace{1em}

```{r m4, fig.height=2, fig.width=6.5, fig.cap="\\label{fig:m4}Difference in treatment effects of free choice manipulation (vs. forced exposure) conditional on exposure to information source that is inconsistent with media preference. Coefficients are based on linear regression models controlling for pre-treatment immigration attitudes, political predispositions, and sociodemographics. Positive coefficients indicate larger treatment effect for voluntary (vs. involuntary) exposure to inconsistent source. 95\\% (thin line) and 90\\% (thick line) confidence intervals based on robust standard errors. Appendix C displays full model results."}
p4
```

To further corroborate this finding, we now directly compare the effect of voluntary and involuntary exposure to inconsistent sources. Specifically, we reduce the sample to include only participants who were exposed to a news source that was inconsistent with their usual media diet. We then run regressions using the same specifications as before, now only including a single treatment indicator for the free choice condition. Note that since this specification omits the control group and instead uses forced exposure to inconsistent sources as the reference category, the coefficients can be directly interpreted as the differences in treatment effects between the free choice and forced exposure condition. The results are displayed in Figure \ref{fig:m4}.

Conditional on exposure to an inconsistent source, there are no clear differences in treatment effects on beliefs and related interpretations. However, participants who were exposed to inconsistent sources in the free choice condition reported more favorable opinions towards immigrants than participants who were exposed to inconsistent sources in the forced exposure condition. This finding is quite remarkable considering the fact that regardless of the news organization, the actual content of the tweet and article was constant across all treatments.

In sum, changing people's minds by giving them free choice over their media diet is not driven by the ability to choose consistent news sources. On the contrary, only participants who voluntarily accessed information from an inconsistent source reported significantly different opinions than the control group. In the next section, we explore potential explanations for this striking result.

<!--JJ comments: in this section, need to say more about why consistent sources are more persuasive for changing interpretations but inconsistent sources are more persuasive when it comes to changing opinions.-->


## What About Self-Selection and Ambivalence?[^5]

[^5]: The analyses in this section were not preregistered and should therefore be considered exploratory.

Discuss ACTE analysis: it is worth noting that the ACTE analysis suggest that people who usually prefer MSNBC are more critical of Fox News than people who usually prefer Fox News.

Much like other studies of information seeking behavior, we find there are subjects who voluntarily seek out information from sources that are counter to our expectations [CITES-Redlawsk??]. We find that these subjects are also more likely to exhibit opinion change/are more receptive to corrective information. <!--briefly recap findings from previous section (1-2 sentences)--> 

We suspect there are two potential explanations for our findings that are at play here. On the one hand, theories of information processing suggest that information effects depend on both the supply of information and the underlying motivation to acquire and carefully evaluate such information (Chaiken, 1980; Delli Carpini & Keeter, 1996). Of these motivations, accuracy motivations tend to increase citizens’ exposure to heterogeneous viewpoints and thus decrease their resistance to persuasion (Levitan &Visser, 2009).<!--see also Pietryka 2016 discussions paper--> These information-seeking motivations are potential indicators of receptivity to new information and thus result in a greater likelihood of updating.

It could also be the case that those viewing information from what we deem as 'inconsistent' with their preferred outlets are simply more ambivalent/have weaker attitudes <!--need to decide what language to use here and be consistent throughout --> about the issue to begin with. The need to defend attitudes is proportionate to the strength of those attitudes (see discussion in Leeper and Slothuus 2014). For instance, Leeper (POQ, year??) finds that those subjects who are motivated to defend prior attitudes polarize over time when presented with new issue-relevant information, while individuals with weaker issue attitudes display opinions that reflect the consideration of new issue-relevant information, even if it is contradictory. <!--could probably summarize this a bit better-->

In order to shed light on the underlying mechanism at play, we provide a secondary analysis leveraging open-ended responses...[what should we find if it's option 1? what do the results look like if it's the latter mechanism at play?]
<!--add analysis of open-ended responses. -->





Most importantly, it is worth noting that conditioning on (in)consistent exposure in the free choice condition makes it difficult to provide a clear causal interpretation of the effects. While our analyses control for political predispositions and pre-treatment immigration attitudes, we cannot fully rule out the possibility that people who self-selected into exposure to an inconsistent source had substantively different attitudes irrespective of the treatment instead of being more receptive to the corrective information<!--they also could be different in how they process new information-->. 

Note that these were not part of the pre-registered hypotheses!

The last analysis in the main text uses the well-established LIWC dictionary [@tausczik2010psychological; @pennebaker2015development] to examine differences in tentative language in two open-ended responses where participants explain their previous assessment of the immigrant community's contribution to society by creating jobs and paying taxes. The goal was to investigate whether the observed opinion change in response to voluntary exposure to inconsistent sources could be explained by the fact that people who chose to access an inconsistent source have more ambivalent immigration attitudes prior to receiving the treatment. Our analysis in the main text suggests that this is unlikely to be the case since there were no significant differences in tentative language between the forced exposure and free choice condition (conditional on exposure to an inconsistent source).

\vspace{1em}

```{r m5, fig.height=2, fig.width=4.5, fig.cap="\\label{fig:m5}Difference in tentative language in open-ended responses of respondents who were exposed to inconsistent information in the free choice and forced exposure condition. Tentative words based on LIWC dictionary, including 95\\% (thin line) and 90\\% (thick line) confidence intervals."}
p5
```

<!-- [^1]: See Appendix D.III for full question wording. -->

# Discussion and Conclusion

The apparent pervasiveness of misinformation across a wide range of political issues is exacerbated by an increasingly polarized media environment where people have unprecedented access to a wide variety of media sources. When it comes to the effectiveness of corrective interventions, revising people's factual *beliefs* is relatively easy, while changing their underlying *opinions* is hard. Yet, previous research in this context neglected the role of selective exposure and endogenous information search as a determinant of the potential attitudinal impact of corrective information.

Our study fills this gap in the literature by employing an experimental design that allows a subset of participants to choose their information source. Holding the actual content constant, we find that the ability to choose news sources facilitates opinion change. However, the effect of people's discretion over their information intake is not driven by their tendency to access sources that are consistent with their usual media diet. Rather, it is the voluntary exposure to inconsistent sources that results in opinion change. Accordingly, encouraging people to voluntarily access alternative sources may be a more effective strategy to combat misinformation than providing fact-checks alone.

Of course, our findings are not without limitations. Most importantly, it is worth noting that conditioning on (in)consistent exposure in the free choice condition makes it difficult to provide a clear causal interpretation of the effects. While our analyses control for political predispositions and pre-treatment immigration attitudes, we cannot fully rule out the possibility that people who self-selected into exposure to an inconsistent source had substantively different attitudes irrespective of the treatment instead of being more receptive to the corrective information<!--they also could be different in how they process new information-->. The fact that we do observe significant treatment effects for the free choice condition (and not for the forced exposure condition) across the entire sample somewhat alleviates this concern, since this overall relationship cannot be explained purely by self-selection into inconsistent exposure. As such, it seems more likely that the patterns are driven by people's underlying openness to consider alternative views than by differences in baseline attitudes. Ultimately, while more work is necessary to corroborate this conclusion, we find at least suggestive evidence that discretion over information sources facilitates opinion change in response to corrective information. In order to further substantiate these findings, we are planning a pre-registered replication of this study focusing on a different policy area and using a larger sample size.

<!-- add discussion of literature on accuracy motivation and related predispositions to be open-minded -->
<!-- mention small sample size in last analysis as additional limitation -->

\clearpage

\parskip=10pt
