---
title: "Reliable Sources? Correcting Misinformation in Polarized Media Environments"
author:
- name: Patrick W Kraft
  affiliation: University of Wisconsin-Milwaukee
  email: kraftp@uwm.edu
- name: Nicholas R. Davis
  affiliation: University of Wisconsin-Milwaukee
  email: nrdavis@uwm.edu
- name: Taraleigh Davis
  affiliation: University of Wisconsin-Milwaukee
  email: taraleig@uwm.edu
- name: Amanda Heideman
  affiliation: University of Wisconsin-Milwaukee
  email: heidem24@uwm.edu
- name: Jason T. Neumeyer
  affiliation: University of Wisconsin-Milwaukee
  email: neumeye6@uwm.edu
- name: Shin Young Park
  affiliation: University of Wisconsin-Milwaukee
  email: parksy@uwm.edu
date: January 28, 2020
published: Working paper.
git-repo: https://github.com/experimentalpolitics/immigration
abstract: >-
  Various important issues at the center of today’s politics--such as immigration or climate change--are imbued with misinformation. A growing body of research therefore explores whether people’s misperceptions can be mitigated by providing corrective information. While such corrections have been shown to reduce factual misinformation, they appear to have little to no effect on underlying attitudes. Our study contributes to this active research area by examining how variations in the source and delivery mode moderate the effectiveness of corrective information. In our pre-registered survey experiment, participants are exposed to a news article published by Fox News or MSNBC, each highlighting the positive economic impact of legal immigration in the United States. While the news content is held constant across sources, our treatment manipulates whether participants are allowed to freely choose a media outlet or are randomly assigned to one of them. Conditional on the delivery mode and news organization, we explore whether the article is effective in correcting factual misperceptions and how it impacts general attitudes towards immigration. Furthermore, we examine differences in the overall engagement with the news article. Our results illustrate how people’s political predispositions and media preferences moderate the effectiveness of corrective information and the likelihood of it being further shared with others (e.g., through social media). The implications of our results for the development of more effective strategies to disseminate corrective information are discussed. 
reference-section-title: References
mainfont: Spectral
sansfont: Open Sans
---



# Lit Review Outline

## Overview: Corrective information literature

Correcting misinformation does not lead to attitude change (but there are mixed findings).

While each of these studies contribute to our understanding of the effect of factual information on issue opinions, the findings are mixed. This inconsistency suggest the need for additional research.

We seek to improve on previous studies in several ways...

### Hopkins et al. 2019

Overview:

- seven original survey experiments (various US samples) that "randomly assign respondents to receive or not receive accurate information about the prevalence of immigrants before reporting attitudes about immigrants and immigration policy"
- information corrects misperception (i.e., reduces estimated size of immigrant population) but only has little and inconsistent impact on attitudes about immigration
- finding is not consistent with theories of power or intergroup threat (they argue it doesn't necessarily cast doubt on the theory itself, but rather suggests that there may be other cognitive mechanisms that explain why people perceive an out-group as threatening)
- "Misperceptions about the size of minority groups may be a consequence, rather than a cause, of attitudes toward those groups."

Comments / Questions:

- good literature review, check some of their citations/discussion of previous results!

### Thompson 2019

@thompson2019might

General finding:

- misinfo can be corrected, but attitudes don't change unless there is considerable more (fact-checked) misinformation than affirmed factual statements (even then effects are small) -> ratio of misinfo/factual matters
- overall, there appears to be mostly symmetry in how supporters of Trump vs. Sanders react (e.g., both are not able to differentiate between factual statement and misinfo prior to receiving the fact-check, although it should be noted that the Sanders-misinfo is qualitatively different from Trump-misinfo). But: supporters of Trump believed significantly more in Trump misinformation than non-supporters, even after receiving corrective info.
- corrective misinformation did not change participants' view of a politician's general veracity, they are bad at keeping a running tally of inaccuracies


Design:

- experiment showing actual statements by Trump/Sanders (some factual, some misinfo), varied the ratio of factual vs. misinfo statements
- atttitudes / beliefs measured pre and post fact-check
- supporter/non-supporter distinction based on feeling-thermometer split
- 2(ratio manipulation)x2(Trump/Sanders)x2(Supporter/non-supporter)x2(pre/post fact check) between-within design
- sample: 1,500 MTurk respondents

Comments / Questions:

- shows useful examples of how to present corrective information for future experimental designs
- analysis clearly done by psychologist, lots of ANOVAs with three-way interactions
- Q: this study focuses on change in feeling towards source (i.e., the politician making false statement) rather than the change in feeling towards the target (i.e., the object the false statement is about, c.f., Hopkins 2019 JOP). Important difference?


## Theoretical Expectations

### Motivated Reasoning
The findings of previous research are perhaps unsurprising. How individuals treat facts and other types of information depends on their incentives (motivation + ability). Reliance on cues/heuristics like ideological predispositions. Absent substantial motivation to accurately process information, individuals interpret new information in light of their extant attitudes. *Lodge & Taber  Bush credibility.

A compelling explanation of this pattern is the tendency to engage in motivated reasoning. Humans = biased information seekers [@kunda1990case] and asymmetric updaters (Sunstein et al 2016). @Taber2006
Lodge & Taber (2006, 2008)

Dalton, Beck, and Huckfeldt (1998) found that perception of news is shaped as much by a person’s political views as by objective content.

Source Credibility 
Additionally, in a time when partisanship colors how people perceive new information, even neutral sources might be less credible than is often presumed (see discussion in Berinsky 2017). @berinsky2018telling

Source credibility profoundly affects social interpretations of information (Lupia and McCubbins 1998). 
Berinsky (2017): Error correction of fake news is mostly likely to be effective when coming from a co-partisan w/ whom one might expect to agree. 

Messenger overwhelms the message: Kuklinski and Hurley (1994) connected the use of ideological heuristics and source cues. They argued that by focusing their attention on the individual political actor, citizens make quick judgments of the information presented to them based largely on the reputation of the speaker. Experimental subjects presented with a message evaluated that message based largely on their opinion of the speaker.




## Summarize/Hypotheses: 

The literature informs us respondents may engage in a biased search process, seeking out information that supports their preconceptions and avoiding evidence that undercuts their beliefs (see Taber and Lodge 2006). This leads to hypothesis 1: When free to choose what information they will expose themselves to, people will seek out confirming over disconfirming arguments.

H2: (information search) Allowing people to choose makes corrective information more effective. -> In allowing for an endogenous information search, we manipulate the information search process. Not only do we expect that people seek confirming info, but those allowed to seek information will be more likely/motivated to update beliefs than those assigned corrective information. *Why though??

Two lines of potential reasoning (discussed in 5/1/19 meeting):
The first is a methodological argument. From this perspective, we can argue that including the endogenous search manipulation is cleaner from a design perspective. This way, we have the comparison between randomly allocating and letting you choose vs. giving friendly or not friendly source. This is important because giving someone a friendly vs. unfriendly source cue depends on how good your measurement is (whether a or b is friendly). We can make an argument that we can get at that measurement and get a prediction but it’s based on an assumption. In reality, there might be diffs in how people select or reveal what they trust. As soon as these potential errors are taken into account, it is compelling to make an arg that its cleaner than trying to find out what’s friendly or unfriendly and then assigning. Ultimately it’s a pure design question.

But is it theoretically something different? Is choosing substantively diff than mech of friendly vs unfriendly source. Is it about control over choosing itself? Big mech is whether you trust info source or not. If it’s the same, need to rethink whether our contribution to the literature is going beyond what the source cue lit has done. 

Ultimately, this manipulation allows us to study how people react to information—most give random info and look at effects. Big diff in info environment is that you choose info you’re exposed to—think about contribution in terms of looking at whether information choice changes effect of information you’re given. Fake news literature? Assumption that as soon they are given info by anyone they are suspicious of it? 

H3: (ideological interaction) Those who receive information from ‘friendly’ sources are more likely to update beliefs. -> We expect that citizens are more likely to alter their attitudes/opinions when the source is perceived as credible (sympathetic to ideological predispositions).
