%!TEX program = xelatex
% \documentclass[11pt,article,oneside]{memoir}
\documentclass[11pt,article,oneside]{memoir}

\usepackage{pandoc/templates/hikma-preamble-xelatex}

% For custom math fonts
\usepackage{unicode-math}

% This stuff has to come before polyglossia and bidi

% Wrap definition list terms
% https://tex.stackexchange.com/a/9763/11851
\usepackage{enumitem}
\setlist[description]{style=unboxed}

\usepackage{fancyvrb}

% This has to come before loading biblatex
\usepackage{polyglossia}
\setdefaultlanguage{english}
\setotherlanguage{arabic}
\newfontfamily\arabicfont[Script = Arabic]{Amiri}

% Bibliography stuff
\usepackage[authordate, backend=biber, noibid,
            autolang=hyphen, bibencoding=inputenc,
            strict, isbn=false, uniquename=false]{biblatex-chicago} % biblatex setup
% No space between bib entries + use smaller font
\setlength\bibitemsep{0pt}
\renewcommand*{\bibfont}{\footnotesize}

%% Fix biblatex's odd preference for using In: by default.
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{%
  \printtext{\bibstring{}\intitlepunct}}}

%% bibnamedash: with Minion Pro the three-emdash lines in the
%% bibliogrpaphy end up separated from one another, which is very
%% annoying. Replace them with a line of appropriate size and weight.
\renewcommand{\bibnamedash}{\rule[3.5pt]{3em}{0.5pt}}

\addbibresource{../../bibliography/Lab.bib}
\setlength\bibhang{\parindent}

% Set the format for footnote numbering and length and size of footnote rule
\footmarkstyle{#1.\,}
\renewcommand*{\footnoterule}{\kern-3pt\hrule width 0.3\columnwidth\kern 4pt}




% memoir does its own subfloats with \subtop and \subbottom. Instead of
% fighting with pandoc-crossref, which outputs \subfloat, just redefine
% \subfloat as \subbottom
\newsubfloat{figure}  % Allow subfloats in figure environment
\let\subfloat\subbottom

\title{\bigskip \bigskip Reliable Sources? Correcting Misinformation in
Polarized Media Environments}

\author{
      \Large Author 1 \newline
    \footnotesize University of Whatever \newline
    \footnotesize \url{author1@example.edu}\vspace*{1.1em}\newline 
     \and 
      \Large Author 2 \newline
    \footnotesize University of Wherever \newline
    \footnotesize \url{author2@example2.edu}\vspace*{1.1em}\newline 
    }

\date{}



% Add PDF metadata
\hypersetup{pdfinfo={
  Title={Reliable Sources? Correcting Misinformation in Polarized Media
Environments},
  Author={Author 1, Author 2},
  Creator={Markdown, pandoc, and TeX}
  % Subject={},
  % Keywords={things, go, here}
}}

\defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}

    \setmainfont[Numbers={Proportional,OldStyle}]{Spectral}
    \setsansfont{Open Sans}
    \setmonofont[Mapping=tex-ansi]{InconsolataGo}
    \setmathfont{Libertinus Math}



\begin{document}
\setkeys{Gin}{width=1\textwidth}
% Deal with verbatim font sizes, since this handles leading better than setting
% a Scale factor in \setmonofont
\fvset{fontsize=\footnotesize}
\RecustomVerbatimEnvironment{verbatim}{Verbatim}{}

\chapterstyle{hikma-article}


\pagestyle{ath} 


\published{January 3, 2020. Working paper.}

\maketitle


\begin{abstract}
\noindent Various important issues at the center of today's
politics--such as immigration or climate change--are imbued with
misinformation. A growing body of research therefore explores whether
people's misperceptions can be mitigated by providing corrective
information. While such corrections have been shown to reduce factual
misinformation, they appear to have little to no effect on underlying
attitudes. Our study contributes to this active research area by
examining how variations in the source and delivery mode moderate the
effectiveness of corrective information. In our pre-registered survey
experiment, participants are exposed to a news article published by Fox
News or MSNBC, each highlighting the positive economic impact of legal
immigration in the United States. While the news content is held
constant across sources, our treatment manipulates whether participants
are allowed to freely choose a media outlet or are randomly assigned to
one of them. Conditional on the delivery mode and news organization, we
explore whether the article is effective in correcting factual
misperceptions and how it impacts general attitudes towards immigration.
Furthermore, we examine differences in the overall engagement with the
news article. Our results illustrate how people's political
predispositions and media preferences moderate the effectiveness of
corrective information and the likelihood of it being further shared
with others (e.g., through social media). The implications of our
results for the development of more effective strategies to disseminate
corrective information are discussed.
\bigskip
\end{abstract}



\hypertarget{lit-review-outline}{%
\section{Lit Review Outline}\label{lit-review-outline}}

\hypertarget{overview-corrective-information-literature}{%
\subsection{Overview: Corrective information
literature}\label{overview-corrective-information-literature}}

Correcting misinformation does not lead to attitude change (but there
are mixed findings).

While each of these studies contribute to our understanding of the
effect of factual information on issue opinions, the findings are mixed.
This inconsistency suggest the need for additional research.

We seek to improve on previous studies in several ways\ldots{}

\hypertarget{hopkins-et-al.-2019}{%
\subsubsection{Hopkins et al.~2019}\label{hopkins-et-al.-2019}}

Overview:

\begin{itemize}
\tightlist
\item
  seven original survey experiments (various US samples) that ``randomly
  assign respondents to receive or not receive accurate information
  about the prevalence of immigrants before reporting attitudes about
  immigrants and immigration policy''
\item
  information corrects misperception (i.e., reduces estimated size of
  immigrant population) but only has little and inconsistent impact on
  attitudes about immigration
\item
  finding is not consistent with theories of power or intergroup threat
  (they argue it doesn't necessarily cast doubt on the theory itself,
  but rather suggests that there may be other cognitive mechanisms that
  explain why people perceive an out-group as threatening)
\item
  ``Misperceptions about the size of minority groups may be a
  consequence, rather than a cause, of attitudes toward those groups.''
\end{itemize}

Comments / Questions:

\begin{itemize}
\tightlist
\item
  good literature review, check some of their citations/discussion of
  previous results!
\end{itemize}

\hypertarget{thompson-2019}{%
\subsubsection{Thompson 2019}\label{thompson-2019}}

\textcite{thompson2019might}

General finding:

\begin{itemize}
\tightlist
\item
  misinfo can be corrected, but attitudes don't change unless there is
  considerable more (fact-checked) misinformation than affirmed factual
  statements (even then effects are small) -\textgreater{} ratio of
  misinfo/factual matters
\item
  overall, there appears to be mostly symmetry in how supporters of
  Trump vs.~Sanders react (e.g., both are not able to differentiate
  between factual statement and misinfo prior to receiving the
  fact-check, although it should be noted that the Sanders-misinfo is
  qualitatively different from Trump-misinfo). But: supporters of Trump
  believed significantly more in Trump misinformation than
  non-supporters, even after receiving corrective info.
\item
  corrective misinformation did not change participants' view of a
  politician's general veracity, they are bad at keeping a running tally
  of inaccuracies
\end{itemize}

Design:

\begin{itemize}
\tightlist
\item
  experiment showing actual statements by Trump/Sanders (some factual,
  some misinfo), varied the ratio of factual vs.~misinfo statements
\item
  atttitudes / beliefs measured pre and post fact-check
\item
  supporter/non-supporter distinction based on feeling-thermometer split
\item
  2(ratio
  manipulation)x2(Trump/Sanders)x2(Supporter/non-supporter)x2(pre/post
  fact check) between-within design
\item
  sample: 1,500 MTurk respondents
\end{itemize}

Comments / Questions:

\begin{itemize}
\tightlist
\item
  shows useful examples of how to present corrective information for
  future experimental designs
\item
  analysis clearly done by psychologist, lots of ANOVAs with three-way
  interactions
\item
  Q: this study focuses on change in feeling towards source (i.e., the
  politician making false statement) rather than the change in feeling
  towards the target (i.e., the object the false statement is about,
  c.f., Hopkins 2019 JOP). Important difference?
\end{itemize}

\hypertarget{theoretical-expectations}{%
\subsection{Theoretical Expectations}\label{theoretical-expectations}}

\hypertarget{motivated-reasoning}{%
\subsubsection{Motivated Reasoning}\label{motivated-reasoning}}

The findings of previous research are perhaps unsurprising. How
individuals treat facts and other types of information depends on their
incentives (motivation + ability). Reliance on cues/heuristics like
ideological predispositions. Absent substantial motivation to accurately
process information, individuals interpret new information in light of
their extant attitudes. *Lodge \& Taber Bush credibility.

A compelling explanation of this pattern is the tendency to engage in
motivated reasoning. Humans = biased information seekers
\autocite{kunda1990case} and asymmetric updaters (Sunstein et al 2016).
\textcite{Taber2006} Lodge \& Taber (2006, 2008)

Dalton, Beck, and Huckfeldt (1998) found that perception of news is
shaped as much by a person's political views as by objective content.

Source Credibility Additionally, in a time when partisanship colors how
people perceive new information, even neutral sources might be less
credible than is often presumed (see discussion in Berinsky 2017).
\textcite{berinsky2018telling}

Source credibility profoundly affects social interpretations of
information (Lupia and McCubbins 1998). Berinsky (2017): Error
correction of fake news is mostly likely to be effective when coming
from a co-partisan w/ whom one might expect to agree.

Messenger overwhelms the message: Kuklinski and Hurley (1994) connected
the use of ideological heuristics and source cues. They argued that by
focusing their attention on the individual political actor, citizens
make quick judgments of the information presented to them based largely
on the reputation of the speaker. Experimental subjects presented with a
message evaluated that message based largely on their opinion of the
speaker.

\hypertarget{summarizehypotheses}{%
\subsection{Summarize/Hypotheses:}\label{summarizehypotheses}}

The literature informs us respondents may engage in a biased search
process, seeking out information that supports their preconceptions and
avoiding evidence that undercuts their beliefs (see Taber and Lodge
2006). This leads to hypothesis 1: When free to choose what information
they will expose themselves to, people will seek out confirming over
disconfirming arguments.

H2: (information search) Allowing people to choose makes corrective
information more effective. -\textgreater{} In allowing for an
endogenous information search, we manipulate the information search
process. Not only do we expect that people seek confirming info, but
those allowed to seek information will be more likely/motivated to
update beliefs than those assigned corrective information. *Why though??

Two lines of potential reasoning (discussed in 5/1/19 meeting): The
first is a methodological argument. From this perspective, we can argue
that including the endogenous search manipulation is cleaner from a
design perspective. This way, we have the comparison between randomly
allocating and letting you choose vs.~giving friendly or not friendly
source. This is important because giving someone a friendly
vs.~unfriendly source cue depends on how good your measurement is
(whether a or b is friendly). We can make an argument that we can get at
that measurement and get a prediction but it's based on an assumption.
In reality, there might be diffs in how people select or reveal what
they trust. As soon as these potential errors are taken into account, it
is compelling to make an arg that its cleaner than trying to find out
what's friendly or unfriendly and then assigning. Ultimately it's a pure
design question.

But is it theoretically something different? Is choosing substantively
diff than mech of friendly vs unfriendly source. Is it about control
over choosing itself? Big mech is whether you trust info source or not.
If it's the same, need to rethink whether our contribution to the
literature is going beyond what the source cue lit has done.

Ultimately, this manipulation allows us to study how people react to
information---most give random info and look at effects. Big diff in
info environment is that you choose info you're exposed to---think about
contribution in terms of looking at whether information choice changes
effect of information you're given. Fake news literature? Assumption
that as soon they are given info by anyone they are suspicious of it?

H3: (ideological interaction) Those who receive information from
`friendly' sources are more likely to update beliefs. -\textgreater{} We
expect that citizens are more likely to alter their attitudes/opinions
when the source is perceived as credible (sympathetic to ideological
predispositions).

\printbibliography[heading=subbibliography, title=References]
\end{document}
